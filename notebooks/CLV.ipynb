{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestrate BigQuery and AutoML tables with Kubeflow pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.gcp as gcp\n",
    "import kfp.notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a base image to be used by lightweight components\n",
    "The image is created by Kaniko Kubernetes service. The image contains the libraries required to interface with BigQuery, Storage and AutoML tables services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a staging directory for Kaniko\n",
    "STAGING_DIR = 'gs://jksandbox/staging'\n",
    "PROJECT_NAME = 'sandbox-235500'\n",
    "# Set the base image name\n",
    "BASE_IMAGE='gcr.io/%s/automltablesbase:dev' % PROJECT_NAME\n",
    "TARGET_IMAGE='gcr.io/%s/automltablescreate:dev' % PROJECT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter docker magic is used to start a Kaniko job. The magic uses a default Kubernetes config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%docker {BASE_IMAGE} {STAGING_DIR}\n",
    "FROM tensorflow/tensorflow:latest-py3\n",
    "RUN pip3 install --upgrade pandas\n",
    "RUN pip3 install --upgrade google-cloud-storage\n",
    "RUN pip3 install --upgrade google-cloud-automl\n",
    "RUN pip3 install --upgrade google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create python lightweight components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data to Big Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "@dsl.python_component(\n",
    "    name='automml_create_dataset',\n",
    "    description='AutoML create dataset',\n",
    "    base_image=BASE_IMAGE\n",
    ")\n",
    "def automl_import_dataset(\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    table_id: str) -> NamedTuple('DatasetInfo', \n",
    "                               [('name', str), \n",
    "                                ('total_rows', int),\n",
    "                                ('total_columns', int)]):\n",
    "    \n",
    "    \n",
    "    print(\"Project ID:\", project_id)\n",
    "    print(\"Dataset ID:\", dataset_id)\n",
    "    print(\"Table ID:\", table_id)\n",
    "    \n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('DatasetInfo', ['name', 'total_rows', 'total_colums'])\n",
    "    return result('test', 1000, 10)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and run a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import json\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='CLVPipeline',\n",
    "    description='CLV Pipeline'\n",
    ")\n",
    "def clv_pipeline(\n",
    "    project_id='', \n",
    "    dataset_id='', \n",
    "    clean_data_query='',\n",
    "    cleaned_data_table_id='',\n",
    "    engineer_features_query='',\n",
    "    features_table_id='',\n",
    "    target='',\n",
    "    feature_list='',\n",
    "    dataset_location='US'\n",
    "):\n",
    "    \n",
    "    BqQueryOp = kfp.components.load_component_from_url(\n",
    "        'https://raw.githubusercontent.com/kubeflow/pipelines/e8524eefb138725fc06600d1956da0f4dd477178/components/gcp/bigquery/query/component.yaml')\n",
    "\n",
    "        \n",
    "    clean_data_op = BqQueryOp(\n",
    "        query=clean_data_query, \n",
    "        project_id=project_id, \n",
    "        dataset_id=dataset_id, \n",
    "        table_id=cleaned_data_table_id, \n",
    "        output_gcs_path='', \n",
    "        dataset_location=dataset_location, \n",
    "        job_config='').apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "    \n",
    "    engineer_features_op = BqQueryOp(\n",
    "        query=engineer_features_query, \n",
    "        project_id=project_id, \n",
    "        dataset_id=dataset_id, \n",
    "        table_id=features_table_id, \n",
    "        output_gcs_path='', \n",
    "        dataset_location=dataset_location, \n",
    "        job_config='').apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "    \n",
    "    engineer_features_op.after(clean_data_op)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pipeline_func = clv_pipeline\n",
    "pipeline_filename = pipeline_func.__name__ + '.tar.gz'\n",
    "\n",
    "kfp.compiler.Compiler().compile(pipeline_func, pipeline_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the pipeline for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_date = '2011-08-08'\n",
    "predict_date = '2011-12-12'\n",
    "project_id = 'sandbox-235500'\n",
    "dataset_id = \"CLVDataset\"\n",
    "max_monetary = \"15000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSELECT\\n  customer_id,\\n  order_date,\\n  order_value,\\n  order_qty_articles\\nFROM\\n(\\n  SELECT\\n    CustomerID AS customer_id,\\n    PARSE_DATE(\"%m/%d/%y\", SUBSTR(InvoiceDate, 0, 8)) AS order_date,\\n    ROUND(SUM(UnitPrice * Quantity), 2) AS order_value,\\n    SUM(Quantity) AS order_qty_articles,\\n    (\\n      SELECT\\n        MAX(PARSE_DATE(\"%m/%d/%y\", SUBSTR(InvoiceDate, 0, 8)))\\n      FROM\\n        `sandbox-235500.CLVDataset.data_source` tl\\n      WHERE\\n        tl.CustomerID = t.CustomerID\\n    ) latest_order\\n  FROM\\n    `sandbox-235500.CLVDataset.data_source` t\\n  GROUP BY\\n      CustomerID,\\n      order_date\\n) a\\n\\nINNER JOIN (\\n  -- Only customers with more than one positive order values before threshold.\\n  SELECT\\n    CustomerID\\n  FROM (\\n    -- Customers and how many positive order values  before threshold.\\n    SELECT\\n      CustomerID,\\n      SUM(positive_value) cnt_positive_value\\n    FROM (\\n      -- Customer with whether order was positive or not at each date.\\n      SELECT\\n        CustomerID,\\n        (\\n          CASE\\n            WHEN SUM(UnitPrice * Quantity) > 0 THEN 1\\n            ELSE 0\\n          END ) positive_value\\n      FROM\\n        `sandbox-235500.CLVDataset.data_source`\\n      WHERE\\n        PARSE_DATE(\"%m/%d/%y\", SUBSTR(InvoiceDate, 0, 8)) < DATE(\"2011-08-08\")\\n      GROUP BY\\n        CustomerID,\\n        SUBSTR(InvoiceDate, 0, 8) )\\n    GROUP BY\\n      CustomerID )\\n  WHERE\\n    cnt_positive_value > 1\\n  ) b\\nON\\n  a.customer_id = b. CustomerID\\n--[START common_clean]\\nWHERE\\n  -- Bought in the past 3 months\\n  DATE_DIFF(DATE(\"2011-12-12\"), latest_order, DAY) <= 90\\n  -- Make sure returns are consistent.\\n  AND (\\n    (order_qty_articles > 0 and order_Value > 0) OR\\n    (order_qty_articles < 0 and order_Value < 0)\\n  )\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT\n",
    "  customer_id,\n",
    "  order_date,\n",
    "  order_value,\n",
    "  order_qty_articles\n",
    "FROM\n",
    "(\n",
    "  SELECT\n",
    "    CustomerID AS customer_id,\n",
    "    PARSE_DATE(\"%m/%d/%y\", SUBSTR(InvoiceDate, 0, 8)) AS order_date,\n",
    "    ROUND(SUM(UnitPrice * Quantity), 2) AS order_value,\n",
    "    SUM(Quantity) AS order_qty_articles,\n",
    "    (\n",
    "      SELECT\n",
    "        MAX(PARSE_DATE(\"%m/%d/%y\", SUBSTR(InvoiceDate, 0, 8)))\n",
    "      FROM\n",
    "        `<<project_id>>.<<dataset_id>>.data_source` tl\n",
    "      WHERE\n",
    "        tl.CustomerID = t.CustomerID\n",
    "    ) latest_order\n",
    "  FROM\n",
    "    `<<project_id>>.<<dataset_id>>.data_source` t\n",
    "  GROUP BY\n",
    "      CustomerID,\n",
    "      order_date\n",
    ") a\n",
    "\n",
    "INNER JOIN (\n",
    "  -- Only customers with more than one positive order values before threshold.\n",
    "  SELECT\n",
    "    CustomerID\n",
    "  FROM (\n",
    "    -- Customers and how many positive order values  before threshold.\n",
    "    SELECT\n",
    "      CustomerID,\n",
    "      SUM(positive_value) cnt_positive_value\n",
    "    FROM (\n",
    "      -- Customer with whether order was positive or not at each date.\n",
    "      SELECT\n",
    "        CustomerID,\n",
    "        (\n",
    "          CASE\n",
    "            WHEN SUM(UnitPrice * Quantity) > 0 THEN 1\n",
    "            ELSE 0\n",
    "          END ) positive_value\n",
    "      FROM\n",
    "        `<<project_id>>.<<dataset_id>>.data_source`\n",
    "      WHERE\n",
    "        PARSE_DATE(\"%m/%d/%y\", SUBSTR(InvoiceDate, 0, 8)) < DATE(\"<<threshold_date>>\")\n",
    "      GROUP BY\n",
    "        CustomerID,\n",
    "        SUBSTR(InvoiceDate, 0, 8) )\n",
    "    GROUP BY\n",
    "      CustomerID )\n",
    "  WHERE\n",
    "    cnt_positive_value > 1\n",
    "  ) b\n",
    "ON\n",
    "  a.customer_id = b. CustomerID\n",
    "--[START common_clean]\n",
    "WHERE\n",
    "  -- Bought in the past 3 months\n",
    "  DATE_DIFF(DATE(\"<<predict_date>>\"), latest_order, DAY) <= 90\n",
    "  -- Make sure returns are consistent.\n",
    "  AND (\n",
    "    (order_qty_articles > 0 and order_Value > 0) OR\n",
    "    (order_qty_articles < 0 and order_Value < 0)\n",
    "  )\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "clean_data_query = QUERY.replace(\"<<threshold_date>>\", threshold_date)\n",
    "clean_data_query = clean_data_query.replace(\"<<predict_date>>\", predict_date)\n",
    "clean_data_query = clean_data_query.replace(\"<<project_id>>\", project_id)\n",
    "clean_data_query = clean_data_query.replace(\"<<dataset_id>>\", dataset_id)\n",
    "clean_data_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSELECT\\n  tf.customer_id,\\n  -- For training period\\n  -- Copying the calculations from Lifetimes where first orders are ignored\\n  -- See https://github.com/CamDavidsonPilon/lifetimes/blob/master/lifetimes/utils.py#L246\\n--[START features_target]\\n  tf.monetary_dnn,\\n  tf.cnt_orders AS frequency_dnn,\\n  tf.cnt_orders - 1 AS frequency_btyd,\\n  tf.recency,\\n  tf.T,\\n  ROUND(tf.recency/cnt_orders, 2) AS time_between,\\n  ROUND(tf.avg_basket_value, 2) AS avg_basket_value,\\n  ROUND(tf.avg_basket_size, 2) AS avg_basket_size,\\n  tf.cnt_returns,\\n  -- Target calculated for overall period\\n  ROUND(tt.target_monetary, 2) as target_monetary\\n--[END features_target]\\nFROM\\n  -- This SELECT uses only data before threshold to make features.\\n  (\\n    SELECT\\n      customer_id,\\n      SUM(order_value) AS monetary_dnn,\\n      DATE_DIFF(MAX(order_date), MIN(order_date), DAY) AS recency,\\n      DATE_DIFF(DATE('2011-08-08'), MIN(order_date), DAY) AS T,\\n      COUNT(DISTINCT order_date) AS cnt_orders,\\n      AVG(order_qty_articles) avg_basket_size,\\n      AVG(order_value) avg_basket_value,\\n      SUM(CASE\\n          WHEN order_value < 1 THEN 1\\n          ELSE 0 END) AS cnt_returns\\n    FROM\\n      -- Makes the order value = 0 if it is the first one\\n      (\\n        SELECT\\n          a.*,\\n          (CASE\\n              WHEN a.order_date = c.order_date_min THEN 0\\n              ELSE a.order_value END) AS order_value_btyd\\n        FROM\\n          `sandbox-235500.CLVDataset.data_cleaned` a\\n        INNER JOIN (\\n          SELECT\\n            customer_id,\\n            MIN(order_date) AS order_date_min\\n          FROM\\n            `sandbox-235500.CLVDataset.data_cleaned`\\n          GROUP BY\\n            customer_id) c\\n        ON\\n          c.customer_id = a.customer_id\\n      )\\n    WHERE\\n      order_date <= DATE('2011-08-08')\\n    GROUP BY\\n      customer_id) tf,\\n\\n  -- This SELECT uses all records to calculate the target (could also use data after threshold )\\n  (\\n    SELECT\\n      customer_id,\\n      SUM(order_value) target_monetary\\n    FROM\\n      `sandbox-235500.CLVDataset.data_cleaned`\\n      --WHERE order_date > DATE('2011-08-08')\\n    GROUP BY\\n      customer_id) tt\\nWHERE\\n  tf.customer_id = tt.customer_id\\n  AND tf.monetary_dnn > 0\\n  AND tf.monetary_dnn <= 15000\\n\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT\n",
    "  tf.customer_id,\n",
    "  -- For training period\n",
    "  -- Copying the calculations from Lifetimes where first orders are ignored\n",
    "  -- See https://github.com/CamDavidsonPilon/lifetimes/blob/master/lifetimes/utils.py#L246\n",
    "--[START features_target]\n",
    "  tf.monetary_dnn,\n",
    "  tf.cnt_orders AS frequency_dnn,\n",
    "  tf.cnt_orders - 1 AS frequency_btyd,\n",
    "  tf.recency,\n",
    "  tf.T,\n",
    "  ROUND(tf.recency/cnt_orders, 2) AS time_between,\n",
    "  ROUND(tf.avg_basket_value, 2) AS avg_basket_value,\n",
    "  ROUND(tf.avg_basket_size, 2) AS avg_basket_size,\n",
    "  tf.cnt_returns,\n",
    "  -- Target calculated for overall period\n",
    "  ROUND(tt.target_monetary, 2) as target_monetary\n",
    "--[END features_target]\n",
    "FROM\n",
    "  -- This SELECT uses only data before threshold to make features.\n",
    "  (\n",
    "    SELECT\n",
    "      customer_id,\n",
    "      SUM(order_value) AS monetary_dnn,\n",
    "      DATE_DIFF(MAX(order_date), MIN(order_date), DAY) AS recency,\n",
    "      DATE_DIFF(DATE('<<threshold_date>>'), MIN(order_date), DAY) AS T,\n",
    "      COUNT(DISTINCT order_date) AS cnt_orders,\n",
    "      AVG(order_qty_articles) avg_basket_size,\n",
    "      AVG(order_value) avg_basket_value,\n",
    "      SUM(CASE\n",
    "          WHEN order_value < 1 THEN 1\n",
    "          ELSE 0 END) AS cnt_returns\n",
    "    FROM\n",
    "      -- Makes the order value = 0 if it is the first one\n",
    "      (\n",
    "        SELECT\n",
    "          a.*,\n",
    "          (CASE\n",
    "              WHEN a.order_date = c.order_date_min THEN 0\n",
    "              ELSE a.order_value END) AS order_value_btyd\n",
    "        FROM\n",
    "          `<<project_id>>.<<dataset_id>>.data_cleaned` a\n",
    "        INNER JOIN (\n",
    "          SELECT\n",
    "            customer_id,\n",
    "            MIN(order_date) AS order_date_min\n",
    "          FROM\n",
    "            `<<project_id>>.<<dataset_id>>.data_cleaned`\n",
    "          GROUP BY\n",
    "            customer_id) c\n",
    "        ON\n",
    "          c.customer_id = a.customer_id\n",
    "      )\n",
    "    WHERE\n",
    "      order_date <= DATE('<<threshold_date>>')\n",
    "    GROUP BY\n",
    "      customer_id) tf,\n",
    "\n",
    "  -- This SELECT uses all records to calculate the target (could also use data after threshold )\n",
    "  (\n",
    "    SELECT\n",
    "      customer_id,\n",
    "      SUM(order_value) target_monetary\n",
    "    FROM\n",
    "      `<<project_id>>.<<dataset_id>>.data_cleaned`\n",
    "      --WHERE order_date > DATE('<<threshold_date>>')\n",
    "    GROUP BY\n",
    "      customer_id) tt\n",
    "WHERE\n",
    "  tf.customer_id = tt.customer_id\n",
    "  AND tf.monetary_dnn > 0\n",
    "  AND tf.monetary_dnn <= <<max_monetary>>\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "engineer_features_query = QUERY.replace(\"<<threshold_date>>\", threshold_date)\n",
    "engineer_features_query = engineer_features_query.replace(\"<<predict_date>>\", predict_date)\n",
    "engineer_features_query = engineer_features_query.replace(\"<<project_id>>\", project_id)\n",
    "engineer_features_query = engineer_features_query.replace(\"<<dataset_id>>\", dataset_id)\n",
    "engineer_features_query = engineer_features_query.replace(\"<<max_monetary>>\", max_monetary)\n",
    "engineer_features_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"http://localhost:8082/api/v1/namespaces/kubeflow/services/ml-pipeline:8888/proxy/#/experiments/details/467df5ba-949c-4781-8478-48fb3ae77859\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://localhost:8082/api/v1/namespaces/kubeflow/services/ml-pipeline:8888/proxy/#/runs/details/5f502bd3-6faf-11e9-b85b-42010a80003c\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': datetime.datetime(2019, 5, 6, 3, 31, 2, tzinfo=tzlocal()),\n",
      " 'description': None,\n",
      " 'error': None,\n",
      " 'finished_at': None,\n",
      " 'id': '5f502bd3-6faf-11e9-b85b-42010a80003c',\n",
      " 'metrics': None,\n",
      " 'name': 'clv_pipeline run',\n",
      " 'pipeline_spec': {'parameters': [{'name': 'feature-list', 'value': '[]'},\n",
      "                                  {'name': 'clean-data-query',\n",
      "                                   'value': '\\n'\n",
      "                                            'SELECT\\n'\n",
      "                                            '  customer_id,\\n'\n",
      "                                            '  order_date,\\n'\n",
      "                                            '  order_value,\\n'\n",
      "                                            '  order_qty_articles\\n'\n",
      "                                            'FROM\\n'\n",
      "                                            '(\\n'\n",
      "                                            '  SELECT\\n'\n",
      "                                            '    CustomerID AS customer_id,\\n'\n",
      "                                            '    PARSE_DATE(\"%m/%d/%y\", '\n",
      "                                            'SUBSTR(InvoiceDate, 0, 8)) AS '\n",
      "                                            'order_date,\\n'\n",
      "                                            '    ROUND(SUM(UnitPrice * '\n",
      "                                            'Quantity), 2) AS order_value,\\n'\n",
      "                                            '    SUM(Quantity) AS '\n",
      "                                            'order_qty_articles,\\n'\n",
      "                                            '    (\\n'\n",
      "                                            '      SELECT\\n'\n",
      "                                            '        '\n",
      "                                            'MAX(PARSE_DATE(\"%m/%d/%y\", '\n",
      "                                            'SUBSTR(InvoiceDate, 0, 8)))\\n'\n",
      "                                            '      FROM\\n'\n",
      "                                            '        '\n",
      "                                            '`sandbox-235500.CLVDataset.data_source` '\n",
      "                                            'tl\\n'\n",
      "                                            '      WHERE\\n'\n",
      "                                            '        tl.CustomerID = '\n",
      "                                            't.CustomerID\\n'\n",
      "                                            '    ) latest_order\\n'\n",
      "                                            '  FROM\\n'\n",
      "                                            '    '\n",
      "                                            '`sandbox-235500.CLVDataset.data_source` '\n",
      "                                            't\\n'\n",
      "                                            '  GROUP BY\\n'\n",
      "                                            '      CustomerID,\\n'\n",
      "                                            '      order_date\\n'\n",
      "                                            ') a\\n'\n",
      "                                            '\\n'\n",
      "                                            'INNER JOIN (\\n'\n",
      "                                            '  -- Only customers with more '\n",
      "                                            'than one positive order values '\n",
      "                                            'before threshold.\\n'\n",
      "                                            '  SELECT\\n'\n",
      "                                            '    CustomerID\\n'\n",
      "                                            '  FROM (\\n'\n",
      "                                            '    -- Customers and how many '\n",
      "                                            'positive order values  before '\n",
      "                                            'threshold.\\n'\n",
      "                                            '    SELECT\\n'\n",
      "                                            '      CustomerID,\\n'\n",
      "                                            '      SUM(positive_value) '\n",
      "                                            'cnt_positive_value\\n'\n",
      "                                            '    FROM (\\n'\n",
      "                                            '      -- Customer with whether '\n",
      "                                            'order was positive or not at each '\n",
      "                                            'date.\\n'\n",
      "                                            '      SELECT\\n'\n",
      "                                            '        CustomerID,\\n'\n",
      "                                            '        (\\n'\n",
      "                                            '          CASE\\n'\n",
      "                                            '            WHEN SUM(UnitPrice * '\n",
      "                                            'Quantity) > 0 THEN 1\\n'\n",
      "                                            '            ELSE 0\\n'\n",
      "                                            '          END ) positive_value\\n'\n",
      "                                            '      FROM\\n'\n",
      "                                            '        '\n",
      "                                            '`sandbox-235500.CLVDataset.data_source`\\n'\n",
      "                                            '      WHERE\\n'\n",
      "                                            '        PARSE_DATE(\"%m/%d/%y\", '\n",
      "                                            'SUBSTR(InvoiceDate, 0, 8)) < '\n",
      "                                            'DATE(\"2011-08-08\")\\n'\n",
      "                                            '      GROUP BY\\n'\n",
      "                                            '        CustomerID,\\n'\n",
      "                                            '        SUBSTR(InvoiceDate, 0, 8) '\n",
      "                                            ')\\n'\n",
      "                                            '    GROUP BY\\n'\n",
      "                                            '      CustomerID )\\n'\n",
      "                                            '  WHERE\\n'\n",
      "                                            '    cnt_positive_value > 1\\n'\n",
      "                                            '  ) b\\n'\n",
      "                                            'ON\\n'\n",
      "                                            '  a.customer_id = b. CustomerID\\n'\n",
      "                                            '--[START common_clean]\\n'\n",
      "                                            'WHERE\\n'\n",
      "                                            '  -- Bought in the past 3 months\\n'\n",
      "                                            '  DATE_DIFF(DATE(\"2011-12-12\"), '\n",
      "                                            'latest_order, DAY) <= 90\\n'\n",
      "                                            '  -- Make sure returns are '\n",
      "                                            'consistent.\\n'\n",
      "                                            '  AND (\\n'\n",
      "                                            '    (order_qty_articles > 0 and '\n",
      "                                            'order_Value > 0) OR\\n'\n",
      "                                            '    (order_qty_articles < 0 and '\n",
      "                                            'order_Value < 0)\\n'\n",
      "                                            '  )\\n'},\n",
      "                                  {'name': 'project-id',\n",
      "                                   'value': 'sandbox-235500'},\n",
      "                                  {'name': 'cleaned-data-table-id',\n",
      "                                   'value': 'data_cleaned'},\n",
      "                                  {'name': 'dataset-id', 'value': 'CLVDataset'},\n",
      "                                  {'name': 'target',\n",
      "                                   'value': 'monetary_target'},\n",
      "                                  {'name': 'features-table-id',\n",
      "                                   'value': 'features'},\n",
      "                                  {'name': 'engineer-features-query',\n",
      "                                   'value': '\\n'\n",
      "                                            'SELECT\\n'\n",
      "                                            '  tf.customer_id,\\n'\n",
      "                                            '  -- For training period\\n'\n",
      "                                            '  -- Copying the calculations '\n",
      "                                            'from Lifetimes where first orders '\n",
      "                                            'are ignored\\n'\n",
      "                                            '  -- See '\n",
      "                                            'https://github.com/CamDavidsonPilon/lifetimes/blob/master/lifetimes/utils.py#L246\\n'\n",
      "                                            '--[START features_target]\\n'\n",
      "                                            '  tf.monetary_dnn,\\n'\n",
      "                                            '  tf.cnt_orders AS '\n",
      "                                            'frequency_dnn,\\n'\n",
      "                                            '  tf.cnt_orders - 1 AS '\n",
      "                                            'frequency_btyd,\\n'\n",
      "                                            '  tf.recency,\\n'\n",
      "                                            '  tf.T,\\n'\n",
      "                                            '  ROUND(tf.recency/cnt_orders, 2) '\n",
      "                                            'AS time_between,\\n'\n",
      "                                            '  ROUND(tf.avg_basket_value, 2) '\n",
      "                                            'AS avg_basket_value,\\n'\n",
      "                                            '  ROUND(tf.avg_basket_size, 2) AS '\n",
      "                                            'avg_basket_size,\\n'\n",
      "                                            '  tf.cnt_returns,\\n'\n",
      "                                            '  -- Target calculated for '\n",
      "                                            'overall period\\n'\n",
      "                                            '  ROUND(tt.target_monetary, 2) as '\n",
      "                                            'target_monetary\\n'\n",
      "                                            '--[END features_target]\\n'\n",
      "                                            'FROM\\n'\n",
      "                                            '  -- This SELECT uses only data '\n",
      "                                            'before threshold to make '\n",
      "                                            'features.\\n'\n",
      "                                            '  (\\n'\n",
      "                                            '    SELECT\\n'\n",
      "                                            '      customer_id,\\n'\n",
      "                                            '      SUM(order_value) AS '\n",
      "                                            'monetary_dnn,\\n'\n",
      "                                            '      DATE_DIFF(MAX(order_date), '\n",
      "                                            'MIN(order_date), DAY) AS '\n",
      "                                            'recency,\\n'\n",
      "                                            '      '\n",
      "                                            \"DATE_DIFF(DATE('2011-08-08'), \"\n",
      "                                            'MIN(order_date), DAY) AS T,\\n'\n",
      "                                            '      COUNT(DISTINCT order_date) '\n",
      "                                            'AS cnt_orders,\\n'\n",
      "                                            '      AVG(order_qty_articles) '\n",
      "                                            'avg_basket_size,\\n'\n",
      "                                            '      AVG(order_value) '\n",
      "                                            'avg_basket_value,\\n'\n",
      "                                            '      SUM(CASE\\n'\n",
      "                                            '          WHEN order_value < 1 '\n",
      "                                            'THEN 1\\n'\n",
      "                                            '          ELSE 0 END) AS '\n",
      "                                            'cnt_returns\\n'\n",
      "                                            '    FROM\\n'\n",
      "                                            '      -- Makes the order value = '\n",
      "                                            '0 if it is the first one\\n'\n",
      "                                            '      (\\n'\n",
      "                                            '        SELECT\\n'\n",
      "                                            '          a.*,\\n'\n",
      "                                            '          (CASE\\n'\n",
      "                                            '              WHEN a.order_date = '\n",
      "                                            'c.order_date_min THEN 0\\n'\n",
      "                                            '              ELSE a.order_value '\n",
      "                                            'END) AS order_value_btyd\\n'\n",
      "                                            '        FROM\\n'\n",
      "                                            '          '\n",
      "                                            '`sandbox-235500.CLVDataset.data_cleaned` '\n",
      "                                            'a\\n'\n",
      "                                            '        INNER JOIN (\\n'\n",
      "                                            '          SELECT\\n'\n",
      "                                            '            customer_id,\\n'\n",
      "                                            '            MIN(order_date) AS '\n",
      "                                            'order_date_min\\n'\n",
      "                                            '          FROM\\n'\n",
      "                                            '            '\n",
      "                                            '`sandbox-235500.CLVDataset.data_cleaned`\\n'\n",
      "                                            '          GROUP BY\\n'\n",
      "                                            '            customer_id) c\\n'\n",
      "                                            '        ON\\n'\n",
      "                                            '          c.customer_id = '\n",
      "                                            'a.customer_id\\n'\n",
      "                                            '      )\\n'\n",
      "                                            '    WHERE\\n'\n",
      "                                            '      order_date <= '\n",
      "                                            \"DATE('2011-08-08')\\n\"\n",
      "                                            '    GROUP BY\\n'\n",
      "                                            '      customer_id) tf,\\n'\n",
      "                                            '\\n'\n",
      "                                            '  -- This SELECT uses all records '\n",
      "                                            'to calculate the target (could '\n",
      "                                            'also use data after threshold )\\n'\n",
      "                                            '  (\\n'\n",
      "                                            '    SELECT\\n'\n",
      "                                            '      customer_id,\\n'\n",
      "                                            '      SUM(order_value) '\n",
      "                                            'target_monetary\\n'\n",
      "                                            '    FROM\\n'\n",
      "                                            '      '\n",
      "                                            '`sandbox-235500.CLVDataset.data_cleaned`\\n'\n",
      "                                            '      --WHERE order_date > '\n",
      "                                            \"DATE('2011-08-08')\\n\"\n",
      "                                            '    GROUP BY\\n'\n",
      "                                            '      customer_id) tt\\n'\n",
      "                                            'WHERE\\n'\n",
      "                                            '  tf.customer_id = '\n",
      "                                            'tt.customer_id\\n'\n",
      "                                            '  AND tf.monetary_dnn > 0\\n'\n",
      "                                            '  AND tf.monetary_dnn <= 15000\\n'\n",
      "                                            '\\n'}],\n",
      "                   'pipeline_id': None,\n",
      "                   'pipeline_manifest': None,\n",
      "                   'workflow_manifest': '{\"apiVersion\": '\n",
      "                                        '\"argoproj.io/v1alpha1\", \"kind\": '\n",
      "                                        '\"Workflow\", \"spec\": {\"arguments\": '\n",
      "                                        '{\"parameters\": [{\"name\": '\n",
      "                                        '\"project-id\", \"value\": \"\"}, {\"name\": '\n",
      "                                        '\"dataset-id\", \"value\": \"\"}, {\"name\": '\n",
      "                                        '\"clean-data-query\", \"value\": \"\"}, '\n",
      "                                        '{\"name\": \"cleaned-data-table-id\", '\n",
      "                                        '\"value\": \"\"}, {\"name\": '\n",
      "                                        '\"engineer-features-query\", \"value\": '\n",
      "                                        '\"\"}, {\"name\": \"features-table-id\", '\n",
      "                                        '\"value\": \"\"}, {\"name\": \"target\", '\n",
      "                                        '\"value\": \"\"}, {\"name\": '\n",
      "                                        '\"feature-list\", \"value\": \"\"}, '\n",
      "                                        '{\"name\": \"dataset-location\", \"value\": '\n",
      "                                        '\"US\"}]}, \"volumes\": [{\"name\": '\n",
      "                                        '\"gcp-credentials\", \"secret\": '\n",
      "                                        '{\"secretName\": \"user-gcp-sa\"}}], '\n",
      "                                        '\"serviceAccountName\": '\n",
      "                                        '\"pipeline-runner\", \"templates\": '\n",
      "                                        '[{\"container\": {\"image\": '\n",
      "                                        '\"gcr.io/ml-pipeline/ml-pipeline-gcp:b0147bdbed9f25212408e0468a475289e80e0406\", '\n",
      "                                        '\"args\": '\n",
      "                                        '[\"kfp_component.google.bigquery\", '\n",
      "                                        '\"query\", \"--query\", '\n",
      "                                        '\"{{inputs.parameters.clean-data-query}}\", '\n",
      "                                        '\"--project_id\", '\n",
      "                                        '\"{{inputs.parameters.project-id}}\", '\n",
      "                                        '\"--dataset_id\", '\n",
      "                                        '\"{{inputs.parameters.dataset-id}}\", '\n",
      "                                        '\"--table_id\", '\n",
      "                                        '\"{{inputs.parameters.cleaned-data-table-id}}\", '\n",
      "                                        '\"--output_gcs_path\", \"\", '\n",
      "                                        '\"--job_config\", \"\"], \"env\": [{\"name\": '\n",
      "                                        '\"KFP_POD_NAME\", \"value\": '\n",
      "                                        '\"{{pod.name}}\"}, {\"name\": '\n",
      "                                        '\"GOOGLE_APPLICATION_CREDENTIALS\", '\n",
      "                                        '\"value\": '\n",
      "                                        '\"/secret/gcp-credentials/user-gcp-sa.json\"}, '\n",
      "                                        '{\"name\": '\n",
      "                                        '\"CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE\", '\n",
      "                                        '\"value\": '\n",
      "                                        '\"/secret/gcp-credentials/user-gcp-sa.json\"}], '\n",
      "                                        '\"command\": [], \"volumeMounts\": '\n",
      "                                        '[{\"name\": \"gcp-credentials\", '\n",
      "                                        '\"mountPath\": '\n",
      "                                        '\"/secret/gcp-credentials\"}]}, '\n",
      "                                        '\"inputs\": {\"parameters\": [{\"name\": '\n",
      "                                        '\"clean-data-query\"}, {\"name\": '\n",
      "                                        '\"cleaned-data-table-id\"}, {\"name\": '\n",
      "                                        '\"dataset-id\"}, {\"name\": '\n",
      "                                        '\"project-id\"}]}, \"name\": '\n",
      "                                        '\"bigquery-query\", \"outputs\": '\n",
      "                                        '{\"parameters\": [{\"name\": '\n",
      "                                        '\"bigquery-query-output-gcs-path\", '\n",
      "                                        '\"valueFrom\": {\"path\": '\n",
      "                                        '\"/tmp/kfp/output/bigquery/query-output-path.txt\"}}], '\n",
      "                                        '\"artifacts\": [{\"name\": '\n",
      "                                        '\"mlpipeline-ui-metadata\", \"s3\": '\n",
      "                                        '{\"accessKeySecret\": {\"name\": '\n",
      "                                        '\"mlpipeline-minio-artifact\", \"key\": '\n",
      "                                        '\"accesskey\"}, \"insecure\": true, '\n",
      "                                        '\"secretKeySecret\": {\"name\": '\n",
      "                                        '\"mlpipeline-minio-artifact\", \"key\": '\n",
      "                                        '\"secretkey\"}, \"endpoint\": '\n",
      "                                        '\"minio-service.kubeflow:9000\", '\n",
      "                                        '\"bucket\": \"mlpipeline\", \"key\": '\n",
      "                                        '\"runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-ui-metadata.tgz\"}, '\n",
      "                                        '\"path\": '\n",
      "                                        '\"/mlpipeline-ui-metadata.json\"}, '\n",
      "                                        '{\"name\": \"mlpipeline-metrics\", \"s3\": '\n",
      "                                        '{\"accessKeySecret\": {\"name\": '\n",
      "                                        '\"mlpipeline-minio-artifact\", \"key\": '\n",
      "                                        '\"accesskey\"}, \"insecure\": true, '\n",
      "                                        '\"secretKeySecret\": {\"name\": '\n",
      "                                        '\"mlpipeline-minio-artifact\", \"key\": '\n",
      "                                        '\"secretkey\"}, \"endpoint\": '\n",
      "                                        '\"minio-service.kubeflow:9000\", '\n",
      "                                        '\"bucket\": \"mlpipeline\", \"key\": '\n",
      "                                        '\"runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-metrics.tgz\"}, '\n",
      "                                        '\"path\": '\n",
      "                                        '\"/mlpipeline-metrics.json\"}]}}, '\n",
      "                                        '{\"container\": {\"image\": '\n",
      "                                        '\"gcr.io/ml-pipeline/ml-pipeline-gcp:b0147bdbed9f25212408e0468a475289e80e0406\", '\n",
      "                                        '\"args\": '\n",
      "                                        '[\"kfp_component.google.bigquery\", '\n",
      "                                        '\"query\", \"--query\", '\n",
      "                                        '\"{{inputs.parameters.engineer-features-query}}\", '\n",
      "                                        '\"--project_id\", '\n",
      "                                        '\"{{inputs.parameters.project-id}}\", '\n",
      "                                        '\"--dataset_id\", '\n",
      "                                        '\"{{inputs.parameters.dataset-id}}\", '\n",
      "                                        '\"--table_id\", '\n",
      "                                        '\"{{inputs.parameters.features-table-id}}\", '\n",
      "                                        '\"--output_gcs_path\", \"\", '\n",
      "                                        '\"--job_config\", \"\"], \"env\": [{\"name\": '\n",
      "                                        '\"KFP_POD_NAME\", \"value\": '\n",
      "                                        '\"{{pod.name}}\"}, {\"name\": '\n",
      "                                        '\"GOOGLE_APPLICATION_CREDENTIALS\", '\n",
      "                                        '\"value\": '\n",
      "                                        '\"/secret/gcp-credentials/user-gcp-sa.json\"}, '\n",
      "                                        '{\"name\": '\n",
      "                                        '\"CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE\", '\n",
      "                                        '\"value\": '\n",
      "                                        '\"/secret/gcp-credentials/user-gcp-sa.json\"}], '\n",
      "                                        '\"command\": [], \"volumeMounts\": '\n",
      "                                        '[{\"name\": \"gcp-credentials\", '\n",
      "                                        '\"mountPath\": '\n",
      "                                        '\"/secret/gcp-credentials\"}]}, '\n",
      "                                        '\"inputs\": {\"parameters\": [{\"name\": '\n",
      "                                        '\"dataset-id\"}, {\"name\": '\n",
      "                                        '\"engineer-features-query\"}, {\"name\": '\n",
      "                                        '\"features-table-id\"}, {\"name\": '\n",
      "                                        '\"project-id\"}]}, \"name\": '\n",
      "                                        '\"bigquery-query-2\", \"outputs\": '\n",
      "                                        '{\"parameters\": [{\"name\": '\n",
      "                                        '\"bigquery-query-2-output-gcs-path\", '\n",
      "                                        '\"valueFrom\": {\"path\": '\n",
      "                                        '\"/tmp/kfp/output/bigquery/query-output-path.txt\"}}], '\n",
      "                                        '\"artifacts\": [{\"name\": '\n",
      "                                        '\"mlpipeline-ui-metadata\", \"s3\": '\n",
      "                                        '{\"accessKeySecret\": {\"name\": '\n",
      "                                        '\"mlpipeline-minio-artifact\", \"key\": '\n",
      "                                        '\"accesskey\"}, \"insecure\": true, '\n",
      "                                        '\"secretKeySecret\": {\"name\": '\n",
      "                                        '\"mlpipeline-minio-artifact\", \"key\": '\n",
      "                                        '\"secretkey\"}, \"endpoint\": '\n",
      "                                        '\"minio-service.kubeflow:9000\", '\n",
      "                                        '\"bucket\": \"mlpipeline\", \"key\": '\n",
      "                                        '\"runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-ui-metadata.tgz\"}, '\n",
      "                                        '\"path\": '\n",
      "                                        '\"/mlpipeline-ui-metadata.json\"}, '\n",
      "                                        '{\"name\": \"mlpipeline-metrics\", \"s3\": '\n",
      "                                        '{\"accessKeySecret\": {\"name\": '\n",
      "                                        '\"mlpipeline-minio-artifact\", \"key\": '\n",
      "                                        '\"accesskey\"}, \"insecure\": true, '\n",
      "                                        '\"secretKeySecret\": {\"name\": '\n",
      "                                        '\"mlpipeline-minio-artifact\", \"key\": '\n",
      "                                        '\"secretkey\"}, \"endpoint\": '\n",
      "                                        '\"minio-service.kubeflow:9000\", '\n",
      "                                        '\"bucket\": \"mlpipeline\", \"key\": '\n",
      "                                        '\"runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-metrics.tgz\"}, '\n",
      "                                        '\"path\": '\n",
      "                                        '\"/mlpipeline-metrics.json\"}]}}, '\n",
      "                                        '{\"inputs\": {\"parameters\": [{\"name\": '\n",
      "                                        '\"clean-data-query\"}, {\"name\": '\n",
      "                                        '\"cleaned-data-table-id\"}, {\"name\": '\n",
      "                                        '\"dataset-id\"}, {\"name\": '\n",
      "                                        '\"engineer-features-query\"}, {\"name\": '\n",
      "                                        '\"features-table-id\"}, {\"name\": '\n",
      "                                        '\"project-id\"}]}, \"name\": '\n",
      "                                        '\"clvpipeline\", \"dag\": {\"tasks\": '\n",
      "                                        '[{\"arguments\": {\"parameters\": '\n",
      "                                        '[{\"name\": \"clean-data-query\", '\n",
      "                                        '\"value\": '\n",
      "                                        '\"{{inputs.parameters.clean-data-query}}\"}, '\n",
      "                                        '{\"name\": \"cleaned-data-table-id\", '\n",
      "                                        '\"value\": '\n",
      "                                        '\"{{inputs.parameters.cleaned-data-table-id}}\"}, '\n",
      "                                        '{\"name\": \"dataset-id\", \"value\": '\n",
      "                                        '\"{{inputs.parameters.dataset-id}}\"}, '\n",
      "                                        '{\"name\": \"project-id\", \"value\": '\n",
      "                                        '\"{{inputs.parameters.project-id}}\"}]}, '\n",
      "                                        '\"name\": \"bigquery-query\", \"template\": '\n",
      "                                        '\"bigquery-query\"}, {\"arguments\": '\n",
      "                                        '{\"parameters\": [{\"name\": '\n",
      "                                        '\"dataset-id\", \"value\": '\n",
      "                                        '\"{{inputs.parameters.dataset-id}}\"}, '\n",
      "                                        '{\"name\": \"engineer-features-query\", '\n",
      "                                        '\"value\": '\n",
      "                                        '\"{{inputs.parameters.engineer-features-query}}\"}, '\n",
      "                                        '{\"name\": \"features-table-id\", '\n",
      "                                        '\"value\": '\n",
      "                                        '\"{{inputs.parameters.features-table-id}}\"}, '\n",
      "                                        '{\"name\": \"project-id\", \"value\": '\n",
      "                                        '\"{{inputs.parameters.project-id}}\"}]}, '\n",
      "                                        '\"dependencies\": [\"bigquery-query\"], '\n",
      "                                        '\"name\": \"bigquery-query-2\", '\n",
      "                                        '\"template\": \"bigquery-query-2\"}]}}], '\n",
      "                                        '\"entrypoint\": \"clvpipeline\"}, '\n",
      "                                        '\"metadata\": {\"generateName\": '\n",
      "                                        '\"clvpipeline-\"}}'},\n",
      " 'resource_references': [{'key': {'id': '467df5ba-949c-4781-8478-48fb3ae77859',\n",
      "                                  'type': 'EXPERIMENT'},\n",
      "                          'relationship': 'OWNER'}],\n",
      " 'scheduled_at': datetime.datetime(1970, 1, 1, 0, 0, tzinfo=tzlocal()),\n",
      " 'status': None,\n",
      " 'storage_state': None}\n"
     ]
    }
   ],
   "source": [
    "#Specify pipeline argument values\n",
    "CLEANED_DATA_TABLE_ID = 'data_cleaned'\n",
    "FEATURES_TABLE_ID = 'features'\n",
    "TARGET_COLUMN_NAME = 'monetary_target'\n",
    "FEATURE_LIST = []\n",
    "\n",
    "arguments = {\n",
    "    'project_id': project_id,\n",
    "    'dataset_id': dataset_id,\n",
    "    'clean_data_query': clean_data_query,\n",
    "    'cleaned_data_table_id': CLEANED_DATA_TABLE_ID,\n",
    "    'engineer_features_query': engineer_features_query,\n",
    "    'features_table_id': FEATURES_TABLE_ID,\n",
    "    'target': TARGET_COLUMN_NAME,\n",
    "    'feature_list': FEATURE_LIST,\n",
    "}\n",
    "\n",
    "\n",
    "HOST = 'http://localhost:8082/api/v1/namespaces/kubeflow/services/ml-pipeline:8888/proxy'\n",
    "EXPERIMENT_NAME = 'CLV_TRAINING'\n",
    "\n",
    "client = kfp.Client(HOST)\n",
    "experiment = client.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "#Submit a pipeline run\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)\n",
    "print(run_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KFP",
   "language": "python",
   "name": "kfp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
