{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#!{sys.executable} -m pip install google-cloud-bigquery[pandas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSELECT\\n  customer_id,\\n  order_date,\\n  order_value,\\n  order_qty_articles\\nFROM\\n(\\n  SELECT\\n    CustomerID AS customer_id,\\n    PARSE_DATE(\"%m/%d/%y\", SUBSTR(InvoiceDate, 0, 8)) AS order_date,\\n    ROUND(SUM(UnitPrice * Quantity), 2) AS order_value,\\n    SUM(Quantity) AS order_qty_articles,\\n    (\\n      SELECT\\n        MAX(PARSE_DATE(\"%m/%d/%y\", SUBSTR(InvoiceDate, 0, 8)))\\n      FROM\\n        `sandbox-235500.CLVDataset.data_source` tl\\n      WHERE\\n        tl.CustomerID = t.CustomerID\\n    ) latest_order\\n  FROM\\n    `sandbox-235500.CLVDataset.data_source` t\\n  GROUP BY\\n      CustomerID,\\n      order_date\\n) a\\n\\nINNER JOIN (\\n  -- Only customers with more than one positive order values before threshold.\\n  SELECT\\n    CustomerID\\n  FROM (\\n    -- Customers and how many positive order values  before threshold.\\n    SELECT\\n      CustomerID,\\n      SUM(positive_value) cnt_positive_value\\n    FROM (\\n      -- Customer with whether order was positive or not at each date.\\n      SELECT\\n        CustomerID,\\n        (\\n          CASE\\n            WHEN SUM(UnitPrice * Quantity) > 0 THEN 1\\n            ELSE 0\\n          END ) positive_value\\n      FROM\\n        `sandbox-235500.CLVDataset.data_source`\\n      WHERE\\n        PARSE_DATE(\"%m/%d/%y\", SUBSTR(InvoiceDate, 0, 8)) < DATE(\"2011-08-08\")\\n      GROUP BY\\n        CustomerID,\\n        SUBSTR(InvoiceDate, 0, 8) )\\n    GROUP BY\\n      CustomerID )\\n  WHERE\\n    cnt_positive_value > 1\\n  ) b\\nON\\n  a.customer_id = b. CustomerID\\n--[START common_clean]\\nWHERE\\n  -- Bought in the past 3 months\\n  DATE_DIFF(DATE(\"2011-12-12\"), latest_order, DAY) <= 90\\n  -- Make sure returns are consistent.\\n  AND (\\n    (order_qty_articles > 0 and order_Value > 0) OR\\n    (order_qty_articles < 0 and order_Value < 0)\\n  )\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT\n",
    "  customer_id,\n",
    "  order_date,\n",
    "  order_value,\n",
    "  order_qty_articles\n",
    "FROM\n",
    "(\n",
    "  SELECT\n",
    "    CustomerID AS customer_id,\n",
    "    PARSE_DATE(\"%m/%d/%y\", SUBSTR(InvoiceDate, 0, 8)) AS order_date,\n",
    "    ROUND(SUM(UnitPrice * Quantity), 2) AS order_value,\n",
    "    SUM(Quantity) AS order_qty_articles,\n",
    "    (\n",
    "      SELECT\n",
    "        MAX(PARSE_DATE(\"%m/%d/%y\", SUBSTR(InvoiceDate, 0, 8)))\n",
    "      FROM\n",
    "        `<<project_id>>.<<dataset_id>>.data_source` tl\n",
    "      WHERE\n",
    "        tl.CustomerID = t.CustomerID\n",
    "    ) latest_order\n",
    "  FROM\n",
    "    `<<project_id>>.<<dataset_id>>.data_source` t\n",
    "  GROUP BY\n",
    "      CustomerID,\n",
    "      order_date\n",
    ") a\n",
    "\n",
    "INNER JOIN (\n",
    "  -- Only customers with more than one positive order values before threshold.\n",
    "  SELECT\n",
    "    CustomerID\n",
    "  FROM (\n",
    "    -- Customers and how many positive order values  before threshold.\n",
    "    SELECT\n",
    "      CustomerID,\n",
    "      SUM(positive_value) cnt_positive_value\n",
    "    FROM (\n",
    "      -- Customer with whether order was positive or not at each date.\n",
    "      SELECT\n",
    "        CustomerID,\n",
    "        (\n",
    "          CASE\n",
    "            WHEN SUM(UnitPrice * Quantity) > 0 THEN 1\n",
    "            ELSE 0\n",
    "          END ) positive_value\n",
    "      FROM\n",
    "        `<<project_id>>.<<dataset_id>>.data_source`\n",
    "      WHERE\n",
    "        PARSE_DATE(\"%m/%d/%y\", SUBSTR(InvoiceDate, 0, 8)) < DATE(\"<<threshold_date>>\")\n",
    "      GROUP BY\n",
    "        CustomerID,\n",
    "        SUBSTR(InvoiceDate, 0, 8) )\n",
    "    GROUP BY\n",
    "      CustomerID )\n",
    "  WHERE\n",
    "    cnt_positive_value > 1\n",
    "  ) b\n",
    "ON\n",
    "  a.customer_id = b. CustomerID\n",
    "--[START common_clean]\n",
    "WHERE\n",
    "  -- Bought in the past 3 months\n",
    "  DATE_DIFF(DATE(\"<<predict_date>>\"), latest_order, DAY) <= 90\n",
    "  -- Make sure returns are consistent.\n",
    "  AND (\n",
    "    (order_qty_articles > 0 and order_Value > 0) OR\n",
    "    (order_qty_articles < 0 and order_Value < 0)\n",
    "  )\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "threshold_date = '2011-08-08'\n",
    "predict_date = '2011-12-12'\n",
    "project_id = 'sandbox-235500'\n",
    "dataset_id = \"CLVDataset\"\n",
    "\n",
    "QUERY = QUERY.replace(\"<<threshold_date>>\", threshold_date)\n",
    "QUERY = QUERY.replace(\"<<predict_date>>\", predict_date)\n",
    "QUERY = QUERY.replace(\"<<project_id>>\", project_id)\n",
    "QUERY = QUERY.replace(\"<<dataset_id>>\", dataset_id)\n",
    "QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(('16525', datetime.date(2011, 5, 10), 124.28, 356), {'customer_id': 0, 'order_date': 1, 'order_value': 2, 'order_qty_articles': 3})\n",
      "Row(('14397', datetime.date(2011, 5, 10), 165.44, 184), {'customer_id': 0, 'order_date': 1, 'order_value': 2, 'order_qty_articles': 3})\n",
      "Row(('16357', datetime.date(2011, 5, 10), 137.9, 22), {'customer_id': 0, 'order_date': 1, 'order_value': 2, 'order_qty_articles': 3})\n",
      "Row(('12901', datetime.date(2011, 5, 10), -208.8, -1200), {'customer_id': 0, 'order_date': 1, 'order_value': 2, 'order_qty_articles': 3})\n",
      "Row(('13592', datetime.date(2011, 5, 10), 95.94, 38), {'customer_id': 0, 'order_date': 1, 'order_value': 2, 'order_qty_articles': 3})\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "table_ref = client.dataset(dataset_id).table('data_cleaned')\n",
    "job_config.destination = table_ref\n",
    "job_config.create_disposition = bigquery.job.CreateDisposition.CREATE_IF_NEEDED\n",
    "job_config.write_disposition = bigquery.job.WriteDisposition.WRITE_TRUNCATE\n",
    "\n",
    "\n",
    "\n",
    "query_job = client.query(QUERY, location='US', job_config=job_config)  # API request\n",
    "rows = iter(query_job.result())  # Waits for query to finish\n",
    "\n",
    "for _ in range(5):\n",
    "    print(next(rows))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSELECT\\n  tf.customer_id,\\n  -- For training period\\n  -- Copying the calculations from Lifetimes where first orders are ignored\\n  -- See https://github.com/CamDavidsonPilon/lifetimes/blob/master/lifetimes/utils.py#L246\\n--[START features_target]\\n  tf.monetary_dnn,\\n  tf.cnt_orders AS frequency_dnn,\\n  tf.cnt_orders - 1 AS frequency_btyd,\\n  tf.recency,\\n  tf.T,\\n  ROUND(tf.recency/cnt_orders, 2) AS time_between,\\n  ROUND(tf.avg_basket_value, 2) AS avg_basket_value,\\n  ROUND(tf.avg_basket_size, 2) AS avg_basket_size,\\n  tf.cnt_returns,\\n  -- Target calculated for overall period\\n  ROUND(tt.target_monetary, 2) as target_monetary\\n--[END features_target]\\nFROM\\n  -- This SELECT uses only data before threshold to make features.\\n  (\\n    SELECT\\n      customer_id,\\n      SUM(order_value) AS monetary_dnn,\\n      DATE_DIFF(MAX(order_date), MIN(order_date), DAY) AS recency,\\n      DATE_DIFF(DATE('2011-08-08'), MIN(order_date), DAY) AS T,\\n      COUNT(DISTINCT order_date) AS cnt_orders,\\n      AVG(order_qty_articles) avg_basket_size,\\n      AVG(order_value) avg_basket_value,\\n      SUM(CASE\\n          WHEN order_value < 1 THEN 1\\n          ELSE 0 END) AS cnt_returns\\n    FROM\\n      -- Makes the order value = 0 if it is the first one\\n      (\\n        SELECT\\n          a.*,\\n          (CASE\\n              WHEN a.order_date = c.order_date_min THEN 0\\n              ELSE a.order_value END) AS order_value_btyd\\n        FROM\\n          `sandbox-235500.CLVDataset.data_cleaned` a\\n        INNER JOIN (\\n          SELECT\\n            customer_id,\\n            MIN(order_date) AS order_date_min\\n          FROM\\n            `sandbox-235500.CLVDataset.data_cleaned`\\n          GROUP BY\\n            customer_id) c\\n        ON\\n          c.customer_id = a.customer_id\\n      )\\n    WHERE\\n      order_date <= DATE('2011-08-08')\\n    GROUP BY\\n      customer_id) tf,\\n\\n  -- This SELECT uses all records to calculate the target (could also use data after threshold )\\n  (\\n    SELECT\\n      customer_id,\\n      SUM(order_value) target_monetary\\n    FROM\\n      `sandbox-235500.CLVDataset.data_cleaned`\\n      --WHERE order_date > DATE('2011-08-08')\\n    GROUP BY\\n      customer_id) tt\\nWHERE\\n  tf.customer_id = tt.customer_id\\n  AND tf.monetary_dnn > 0\\n  AND tf.monetary_dnn <= 15000\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT\n",
    "  tf.customer_id,\n",
    "  -- For training period\n",
    "  -- Copying the calculations from Lifetimes where first orders are ignored\n",
    "  -- See https://github.com/CamDavidsonPilon/lifetimes/blob/master/lifetimes/utils.py#L246\n",
    "--[START features_target]\n",
    "  tf.monetary_dnn,\n",
    "  tf.cnt_orders AS frequency_dnn,\n",
    "  tf.cnt_orders - 1 AS frequency_btyd,\n",
    "  tf.recency,\n",
    "  tf.T,\n",
    "  ROUND(tf.recency/cnt_orders, 2) AS time_between,\n",
    "  ROUND(tf.avg_basket_value, 2) AS avg_basket_value,\n",
    "  ROUND(tf.avg_basket_size, 2) AS avg_basket_size,\n",
    "  tf.cnt_returns,\n",
    "  -- Target calculated for overall period\n",
    "  ROUND(tt.target_monetary, 2) as target_monetary\n",
    "--[END features_target]\n",
    "FROM\n",
    "  -- This SELECT uses only data before threshold to make features.\n",
    "  (\n",
    "    SELECT\n",
    "      customer_id,\n",
    "      SUM(order_value) AS monetary_dnn,\n",
    "      DATE_DIFF(MAX(order_date), MIN(order_date), DAY) AS recency,\n",
    "      DATE_DIFF(DATE('<<threshold_date>>'), MIN(order_date), DAY) AS T,\n",
    "      COUNT(DISTINCT order_date) AS cnt_orders,\n",
    "      AVG(order_qty_articles) avg_basket_size,\n",
    "      AVG(order_value) avg_basket_value,\n",
    "      SUM(CASE\n",
    "          WHEN order_value < 1 THEN 1\n",
    "          ELSE 0 END) AS cnt_returns\n",
    "    FROM\n",
    "      -- Makes the order value = 0 if it is the first one\n",
    "      (\n",
    "        SELECT\n",
    "          a.*,\n",
    "          (CASE\n",
    "              WHEN a.order_date = c.order_date_min THEN 0\n",
    "              ELSE a.order_value END) AS order_value_btyd\n",
    "        FROM\n",
    "          `<<project_id>>.<<dataset_id>>.data_cleaned` a\n",
    "        INNER JOIN (\n",
    "          SELECT\n",
    "            customer_id,\n",
    "            MIN(order_date) AS order_date_min\n",
    "          FROM\n",
    "            `<<project_id>>.<<dataset_id>>.data_cleaned`\n",
    "          GROUP BY\n",
    "            customer_id) c\n",
    "        ON\n",
    "          c.customer_id = a.customer_id\n",
    "      )\n",
    "    WHERE\n",
    "      order_date <= DATE('<<threshold_date>>')\n",
    "    GROUP BY\n",
    "      customer_id) tf,\n",
    "\n",
    "  -- This SELECT uses all records to calculate the target (could also use data after threshold )\n",
    "  (\n",
    "    SELECT\n",
    "      customer_id,\n",
    "      SUM(order_value) target_monetary\n",
    "    FROM\n",
    "      `<<project_id>>.<<dataset_id>>.data_cleaned`\n",
    "      --WHERE order_date > DATE('<<threshold_date>>')\n",
    "    GROUP BY\n",
    "      customer_id) tt\n",
    "WHERE\n",
    "  tf.customer_id = tt.customer_id\n",
    "  AND tf.monetary_dnn > 0\n",
    "  AND tf.monetary_dnn <= <<max_monetary>>\n",
    "\n",
    "'''\n",
    "\n",
    "max_monetary = \"15000\"\n",
    "\n",
    "QUERY = QUERY.replace(\"<<threshold_date>>\", threshold_date)\n",
    "QUERY = QUERY.replace(\"<<predict_date>>\", predict_date)\n",
    "QUERY = QUERY.replace(\"<<project_id>>\", project_id)\n",
    "QUERY = QUERY.replace(\"<<dataset_id>>\", dataset_id)\n",
    "QUERY = QUERY.replace(\"<<max_monetary>>\", max_monetary)\n",
    "QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(('13461', 884.2, 2, 1, 25, 40, 12.5, 442.1, 418.0, 0, 1445.0), {'customer_id': 0, 'monetary_dnn': 1, 'frequency_dnn': 2, 'frequency_btyd': 3, 'recency': 4, 'T': 5, 'time_between': 6, 'avg_basket_value': 7, 'avg_basket_size': 8, 'cnt_returns': 9, 'target_monetary': 10})\n",
      "Row(('16442', 437.03, 2, 1, 133, 237, 66.5, 218.51, 177.0, 0, 616.79), {'customer_id': 0, 'monetary_dnn': 1, 'frequency_dnn': 2, 'frequency_btyd': 3, 'recency': 4, 'T': 5, 'time_between': 6, 'avg_basket_value': 7, 'avg_basket_size': 8, 'cnt_returns': 9, 'target_monetary': 10})\n",
      "Row(('14456', 636.65, 2, 1, 11, 19, 5.5, 318.32, 288.0, 0, 3047.63), {'customer_id': 0, 'monetary_dnn': 1, 'frequency_dnn': 2, 'frequency_btyd': 3, 'recency': 4, 'T': 5, 'time_between': 6, 'avg_basket_value': 7, 'avg_basket_size': 8, 'cnt_returns': 9, 'target_monetary': 10})\n",
      "Row(('17516', 455.21, 2, 1, 68, 162, 34.0, 227.6, 154.5, 0, 768.08), {'customer_id': 0, 'monetary_dnn': 1, 'frequency_dnn': 2, 'frequency_btyd': 3, 'recency': 4, 'T': 5, 'time_between': 6, 'avg_basket_value': 7, 'avg_basket_size': 8, 'cnt_returns': 9, 'target_monetary': 10})\n",
      "Row(('17420', 391.51, 2, 1, 202, 250, 101.0, 195.75, 84.5, 0, 598.83), {'customer_id': 0, 'monetary_dnn': 1, 'frequency_dnn': 2, 'frequency_btyd': 3, 'recency': 4, 'T': 5, 'time_between': 6, 'avg_basket_value': 7, 'avg_basket_size': 8, 'cnt_returns': 9, 'target_monetary': 10})\n"
     ]
    }
   ],
   "source": [
    "feature_table = 'features'\n",
    "project_id = 'sandbox-235500'\n",
    "dataset_id = \"CLVDataset\"\n",
    "\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "table_ref = client.dataset(dataset_id).table(feature_table)\n",
    "job_config.destination = table_ref\n",
    "job_config.create_disposition = bigquery.job.CreateDisposition.CREATE_IF_NEEDED\n",
    "job_config.write_disposition = bigquery.job.WriteDisposition.WRITE_TRUNCATE\n",
    "\n",
    "query_job = client.query(QUERY, location='US', job_config=job_config)  # API request\n",
    "rows = iter(query_job.result())  # Waits for query to finish\n",
    "\n",
    "\n",
    "for _ in range(5):\n",
    "    print(next(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KFP",
   "language": "python",
   "name": "kfp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
