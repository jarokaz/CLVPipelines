{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import compiler\n",
    "import kfp.dsl as dsl\n",
    "import kfp.gcp as gcp\n",
    "import kfp.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'sandbox-235500'\n",
    "BASE_IMAGE = 'gcr.io/{}/automltablesbase:dev'.format(PROJECT_NAME)\n",
    "STAGING_GCS_PATH = 'gs://{}/staging'.format(PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'WITH\\n  order_summaries as (\\n    SELECT\\n      a.customer_id,\\n      a.order_date,\\n      a.order_value,\\n      a.order_qty_articles\\n    FROM\\n    (\\n      SELECT\\n        customer_id,\\n        order_date,\\n        ROUND(SUM(unit_price * quantity), 2) AS order_value,\\n        SUM(quantity) AS order_qty_articles,\\n        (\\n          SELECT\\n            MAX(order_date)\\n          FROM\\n            `{transactions_table_id}` tl\\n          WHERE\\n            tl.customer_id = t.customer_id\\n        ) latest_order\\n      FROM\\n        `{transactions_table_id}` t\\n      GROUP BY\\n          customer_id,\\n          order_date\\n    ) a\\n\\n    INNER JOIN (\\n      -- Only customers with more than one positive order values before threshold.\\n      SELECT\\n        customer_id\\n      FROM (\\n        -- Customers and how many positive order values  before threshold.\\n        SELECT\\n          customer_id,\\n          SUM(positive_value) cnt_positive_value\\n        FROM (\\n          -- Customer with whether order was positive or not at each date.\\n          SELECT\\n            customer_id,\\n            (\\n              CASE\\n                WHEN SUM(unit_price * quantity) > 0 THEN 1\\n                ELSE 0\\n              END ) positive_value\\n          FROM\\n            `{transactions_table_id}`\\n          WHERE\\n            order_date < DATE(\"{threshold_date}\")\\n          GROUP BY\\n            customer_id,\\n            order_date)\\n        GROUP BY\\n          customer_id )\\n      WHERE\\n        cnt_positive_value > 1\\n      ) b\\n    ON\\n      a.customer_id = b.customer_id\\n    --[START common_clean]\\n    WHERE\\n      -- Bought in the past 3 months\\n      DATE_DIFF(DATE(\"{predict_end}\"), latest_order, DAY) <= 90\\n      -- Make sure returns are consistent.\\n      AND (\\n        (order_qty_articles > 0 and order_Value > 0) OR\\n        (order_qty_articles < 0 and order_Value < 0)\\n      ))\\n          \\nSELECT\\n  tf.customer_id,\\n  -- For training period\\n  -- Copying the calculations from Lifetimes where first orders are ignored\\n  -- See https://github.com/CamDavidsonPilon/lifetimes/blob/master/lifetimes/utils.py#L246\\n--[START features_target]\\n  ROUND(tf.monetary, 2) as monetary,\\n  tf.cnt_orders AS frequency,\\n  tf.recency,\\n  tf.T,\\n  ROUND(tf.recency/cnt_orders, 2) AS time_between,\\n  ROUND(tf.avg_basket_value, 2) AS avg_basket_value,\\n  ROUND(tf.avg_basket_size, 2) AS avg_basket_size,\\n  tf.cnt_returns,\\n  -- Target calculated for overall period\\n  ROUND(tt.target_monetary, 2) as target_monetary\\n--[END features_target]\\nFROM\\n  -- This SELECT uses only data before threshold to make features.\\n  (\\n    SELECT\\n      customer_id,\\n      SUM(order_value) AS monetary,\\n      DATE_DIFF(MAX(order_date), MIN(order_date), DAY) AS recency,\\n      DATE_DIFF(DATE(\\'{threshold_date}\\'), MIN(order_date), DAY) AS T,\\n      COUNT(DISTINCT order_date) AS cnt_orders,\\n      AVG(order_qty_articles) avg_basket_size,\\n      AVG(order_value) avg_basket_value,\\n      SUM(CASE\\n          WHEN order_value < 1 THEN 1\\n          ELSE 0 END) AS cnt_returns\\n    FROM\\n      -- Makes the order value = 0 if it is the first one\\n      (\\n        SELECT\\n          a.*,\\n          (CASE\\n              WHEN a.order_date = c.order_date_min THEN 0\\n              ELSE a.order_value END) AS order_value_btyd\\n        FROM\\n          order_summaries a\\n        INNER JOIN (\\n          SELECT\\n            customer_id,\\n            MIN(order_date) AS order_date_min\\n          FROM\\n            order_summaries\\n          GROUP BY\\n            customer_id) c\\n        ON\\n          c.customer_id = a.customer_id\\n      )\\n    WHERE\\n      order_date <= DATE(\\'{threshold_date}\\')\\n    GROUP BY\\n      customer_id) tf,\\n\\n  -- This SELECT uses all records to calculate the target (could also use data after threshold )\\n  (\\n    SELECT\\n      customer_id,\\n      SUM(order_value) target_monetary\\n    FROM\\n      order_summaries\\n      --WHERE order_date > DATE(\\'{threshold_date}\\')\\n    GROUP BY\\n      customer_id) tt\\nWHERE\\n  tf.customer_id = tt.customer_id\\n  AND tf.monetary > 0\\n  AND tf.monetary <= {max_monetary}'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "blob = storage.Client(PROJECT_NAME).get_bucket('sandbox-235500').blob('clv-sql-templates/creandbox-235500/clv-sql-templates/create_features.sql')\n",
    "\n",
    "\n",
    "query_template = blob.download_as_string()\n",
    "\n",
    "query_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@kfp.dsl.python_component(name='Data preparation', base_image=BASE_IMAGE)\n",
    "def prepare_features(\n",
    "    project_id: str,\n",
    "    data_source_id: str,\n",
    "    threshold_date: str,\n",
    "    predict_end: str,\n",
    "    max_monetary: str,\n",
    "    dest_dataset_id: str,\n",
    "    dest_table_id: str,\n",
    "    query_template_uri: str \n",
    "    ) -> str:\n",
    "    \n",
    "    import logging\n",
    "    from google.cloud import bigquery\n",
    "    from google.cloud import storage\n",
    "    \n",
    "    # Load query template\n",
    "    blob = storage.Client(project_id).get_bucket('sandbox-235500').blob('clv-sql-templates/creandbox-235500/clv-sql-templates/create_features.sql')\n",
    "\n",
    "    \n",
    "    return\n",
    "\n",
    "    client = bigquery.Client(project=project_id)\n",
    "    \n",
    "    # If table_id not passed create a unique table name\n",
    "    if not table_id:\n",
    "        table_id = 'output_{}'.format(uuid.uuid4().hex)\n",
    "        \n",
    "    # Configure BQ to write an output to a destination table\n",
    "    job_config = bigquery.QueryJobConfig(\n",
    "        destination=client.dataset(dataset_id).table(table_id),\n",
    "        create_disposition=bigquery.job.CreateDisposition.CREATE_IF_NEEDED,\n",
    "        write_disposition=bigquery.job.WriteDisposition.WRITE_TRUNCATE)\n",
    "        \n",
    "    # Execute the query and wait for the query to finish\n",
    "    client.query(query, job_config).result()\n",
    "    \n",
    "    # Return the full ID of the destination table\n",
    "    return \"{}.{}.{}\".format(\n",
    "        project_id, \n",
    "        dataset_id, \n",
    "        table_id)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://sandbox-235500/clv-sql-templates/create_features.sql\n"
     ]
    }
   ],
   "source": [
    "project_id = 'sandbox-235500'\n",
    "data_source_id = 'sandbox-235500.CLVDataset.transactions'\n",
    "dest_dataset_id = 'CLVDataset'\n",
    "dest_table_id = 'test'\n",
    "threshold_date = '2011-08-08'\n",
    "predict_end = '2011-12-12'\n",
    "max_monetary = '15000'\n",
    "query_template_uri = 'gs://sandbox-235500/clv-sql-templates/create_features.sql'\n",
    "\n",
    "prepare_features_result = prepare_features(\n",
    "        project_id=project_id,\n",
    "        data_source_id=data_source_id,\n",
    "        threshold_date=threshold_date,\n",
    "        predict_end=predict_end,\n",
    "        max_monetary=max_monetary,\n",
    "        dest_dataset_id=dest_dataset_id,\n",
    "        dest_table_id=dest_table_id,\n",
    "        query_template_uri=query_template_uri\n",
    "        )\n",
    "\n",
    "prepare_features_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.build_python_component(\n",
    "    component_func=prepare_features,\n",
    "    staging_gcs_path=STAGING_GCS_PATH,\n",
    "    target_component_file='component-prepare-features.yaml',\n",
    "    target_image='gcr.io/{}/component-prepare-features:latest'.format(PROJECT_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_TEMPLATE_URI = 'gs://sandbox-235500/clv-sql-templates/create_features.sql'\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='CLVTrainingPipeline',\n",
    "    description='CLV Training Pipeline'\n",
    ")\n",
    "def clv_pipeline(\n",
    "    project_id='', \n",
    "    data_source_id='',\n",
    "    dest_dataset_id='', \n",
    "    dest_table_id='',\n",
    "    threshold_date='',\n",
    "    predict_end='',\n",
    "    max_monetary=15000,\n",
    "    automl_dataset_location='us-central1'\n",
    "):\n",
    "\n",
    "\n",
    "    prepare_features_op = kfp.components.load_component('component-prepare-features.yaml')\n",
    "    \n",
    "    prepare_features_task = prepare_features_op(\n",
    "        project_id=project_id,\n",
    "        data_source_id=data_source_id,\n",
    "        threshold_date=threshold_date,\n",
    "        predict_end=predict_end,\n",
    "        max_monetary=max_monetary,\n",
    "        dest_dataset_id=dest_dataset_id,\n",
    "        dest_table_id=dest_table_id,\n",
    "        query_template_uri=QUERY_TEMPLATE_URI\n",
    "        )\n",
    "    \n",
    "    \n",
    "\n",
    "pipeline_func = clv_pipeline\n",
    "pipeline_filename = pipeline_func.__name__ + '.tar.gz'\n",
    "\n",
    "kfp.compiler.Compiler().compile(pipeline_func, pipeline_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"http://localhost:8082/api/v1/namespaces/kubeflow/services/ml-pipeline:8888/proxy/#/experiments/details/ce5537eb-139c-4dad-b144-8ad8519f8e7c\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://localhost:8082/api/v1/namespaces/kubeflow/services/ml-pipeline:8888/proxy/#/runs/details/11d800f1-7379-11e9-bf64-42010a800073\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': datetime.datetime(2019, 5, 10, 23, 12, 23, tzinfo=tzlocal()),\n",
      " 'description': None,\n",
      " 'error': None,\n",
      " 'finished_at': None,\n",
      " 'id': '11d800f1-7379-11e9-bf64-42010a800073',\n",
      " 'metrics': None,\n",
      " 'name': 'clv_pipeline run',\n",
      " 'pipeline_spec': {'parameters': [{'name': 'dest-dataset-id',\n",
      "                                   'value': 'CLVDataset'},\n",
      "                                  {'name': 'project-id',\n",
      "                                   'value': 'sandbox-235500'},\n",
      "                                  {'name': 'max-monetary', 'value': '15000'},\n",
      "                                  {'name': 'threshold-date',\n",
      "                                   'value': '2011-08-08'},\n",
      "                                  {'name': 'predict-end',\n",
      "                                   'value': '2011-12-12'},\n",
      "                                  {'name': 'data-source-id',\n",
      "                                   'value': 'sandbox-235500.CLVDataset.transactions'},\n",
      "                                  {'name': 'dest-table-id', 'value': 'test'}],\n",
      "                   'pipeline_id': None,\n",
      "                   'pipeline_manifest': None,\n",
      "                   'workflow_manifest': '{\"metadata\": {\"generateName\": '\n",
      "                                        '\"clvtrainingpipeline-\"}, '\n",
      "                                        '\"apiVersion\": \"argoproj.io/v1alpha1\", '\n",
      "                                        '\"spec\": {\"templates\": [{\"dag\": '\n",
      "                                        '{\"tasks\": [{\"arguments\": '\n",
      "                                        '{\"parameters\": [{\"value\": '\n",
      "                                        '\"{{inputs.parameters.data-source-id}}\", '\n",
      "                                        '\"name\": \"data-source-id\"}, {\"value\": '\n",
      "                                        '\"{{inputs.parameters.dest-dataset-id}}\", '\n",
      "                                        '\"name\": \"dest-dataset-id\"}, {\"value\": '\n",
      "                                        '\"{{inputs.parameters.dest-table-id}}\", '\n",
      "                                        '\"name\": \"dest-table-id\"}, {\"value\": '\n",
      "                                        '\"{{inputs.parameters.max-monetary}}\", '\n",
      "                                        '\"name\": \"max-monetary\"}, {\"value\": '\n",
      "                                        '\"{{inputs.parameters.predict-end}}\", '\n",
      "                                        '\"name\": \"predict-end\"}, {\"value\": '\n",
      "                                        '\"{{inputs.parameters.project-id}}\", '\n",
      "                                        '\"name\": \"project-id\"}, {\"value\": '\n",
      "                                        '\"{{inputs.parameters.threshold-date}}\", '\n",
      "                                        '\"name\": \"threshold-date\"}]}, \"name\": '\n",
      "                                        '\"data-preparation\", \"template\": '\n",
      "                                        '\"data-preparation\"}]}, \"inputs\": '\n",
      "                                        '{\"parameters\": [{\"name\": '\n",
      "                                        '\"data-source-id\"}, {\"name\": '\n",
      "                                        '\"dest-dataset-id\"}, {\"name\": '\n",
      "                                        '\"dest-table-id\"}, {\"name\": '\n",
      "                                        '\"max-monetary\"}, {\"name\": '\n",
      "                                        '\"predict-end\"}, {\"name\": '\n",
      "                                        '\"project-id\"}, {\"name\": '\n",
      "                                        '\"threshold-date\"}]}, \"name\": '\n",
      "                                        '\"clvtrainingpipeline\"}, {\"outputs\": '\n",
      "                                        '{\"parameters\": [{\"valueFrom\": '\n",
      "                                        '{\"path\": \"/outputs/output/data\"}, '\n",
      "                                        '\"name\": \"data-preparation-output\"}], '\n",
      "                                        '\"artifacts\": [{\"optional\": true, '\n",
      "                                        '\"path\": '\n",
      "                                        '\"/mlpipeline-ui-metadata.json\", \"s3\": '\n",
      "                                        '{\"secretKeySecret\": {\"key\": '\n",
      "                                        '\"secretkey\", \"name\": '\n",
      "                                        '\"mlpipeline-minio-artifact\"}, '\n",
      "                                        '\"endpoint\": '\n",
      "                                        '\"minio-service.kubeflow:9000\", '\n",
      "                                        '\"bucket\": \"mlpipeline\", '\n",
      "                                        '\"accessKeySecret\": {\"key\": '\n",
      "                                        '\"accesskey\", \"name\": '\n",
      "                                        '\"mlpipeline-minio-artifact\"}, \"key\": '\n",
      "                                        '\"runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-ui-metadata.tgz\", '\n",
      "                                        '\"insecure\": true}, \"name\": '\n",
      "                                        '\"mlpipeline-ui-metadata\"}, '\n",
      "                                        '{\"optional\": true, \"path\": '\n",
      "                                        '\"/mlpipeline-metrics.json\", \"s3\": '\n",
      "                                        '{\"secretKeySecret\": {\"key\": '\n",
      "                                        '\"secretkey\", \"name\": '\n",
      "                                        '\"mlpipeline-minio-artifact\"}, '\n",
      "                                        '\"endpoint\": '\n",
      "                                        '\"minio-service.kubeflow:9000\", '\n",
      "                                        '\"bucket\": \"mlpipeline\", '\n",
      "                                        '\"accessKeySecret\": {\"key\": '\n",
      "                                        '\"accesskey\", \"name\": '\n",
      "                                        '\"mlpipeline-minio-artifact\"}, \"key\": '\n",
      "                                        '\"runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-metrics.tgz\", '\n",
      "                                        '\"insecure\": true}, \"name\": '\n",
      "                                        '\"mlpipeline-metrics\"}]}, \"container\": '\n",
      "                                        '{\"args\": '\n",
      "                                        '[\"{{inputs.parameters.project-id}}\", '\n",
      "                                        '\"{{inputs.parameters.data-source-id}}\", '\n",
      "                                        '\"{{inputs.parameters.threshold-date}}\", '\n",
      "                                        '\"{{inputs.parameters.predict-end}}\", '\n",
      "                                        '\"{{inputs.parameters.max-monetary}}\", '\n",
      "                                        '\"{{inputs.parameters.dest-dataset-id}}\", '\n",
      "                                        '\"{{inputs.parameters.dest-table-id}}\", '\n",
      "                                        '\"gs://sandbox-235500/clv-sql-templates/create_features.sql\", '\n",
      "                                        '\"/outputs/output/data\"], \"image\": '\n",
      "                                        '\"gcr.io/sandbox-235500/component-prepare-features:latest\", '\n",
      "                                        '\"command\": []}, \"inputs\": '\n",
      "                                        '{\"parameters\": [{\"name\": '\n",
      "                                        '\"data-source-id\"}, {\"name\": '\n",
      "                                        '\"dest-dataset-id\"}, {\"name\": '\n",
      "                                        '\"dest-table-id\"}, {\"name\": '\n",
      "                                        '\"max-monetary\"}, {\"name\": '\n",
      "                                        '\"predict-end\"}, {\"name\": '\n",
      "                                        '\"project-id\"}, {\"name\": '\n",
      "                                        '\"threshold-date\"}]}, \"name\": '\n",
      "                                        '\"data-preparation\"}], \"arguments\": '\n",
      "                                        '{\"parameters\": [{\"value\": \"\", \"name\": '\n",
      "                                        '\"project-id\"}, {\"value\": \"\", \"name\": '\n",
      "                                        '\"data-source-id\"}, {\"value\": \"\", '\n",
      "                                        '\"name\": \"dest-dataset-id\"}, {\"value\": '\n",
      "                                        '\"\", \"name\": \"dest-table-id\"}, '\n",
      "                                        '{\"value\": \"\", \"name\": '\n",
      "                                        '\"threshold-date\"}, {\"value\": \"\", '\n",
      "                                        '\"name\": \"predict-end\"}, {\"value\": '\n",
      "                                        '\"15000\", \"name\": \"max-monetary\"}, '\n",
      "                                        '{\"value\": \"us-central1\", \"name\": '\n",
      "                                        '\"automl-dataset-location\"}]}, '\n",
      "                                        '\"entrypoint\": \"clvtrainingpipeline\", '\n",
      "                                        '\"serviceAccountName\": '\n",
      "                                        '\"pipeline-runner\"}, \"kind\": '\n",
      "                                        '\"Workflow\"}'},\n",
      " 'resource_references': [{'key': {'id': 'ce5537eb-139c-4dad-b144-8ad8519f8e7c',\n",
      "                                  'type': 'EXPERIMENT'},\n",
      "                          'relationship': 'OWNER'}],\n",
      " 'scheduled_at': datetime.datetime(1970, 1, 1, 0, 0, tzinfo=tzlocal()),\n",
      " 'status': None,\n",
      " 'storage_state': None}\n"
     ]
    }
   ],
   "source": [
    "#Specify pipeline argument values\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT name, SUM(number) as total\n",
    "    FROM `bigquery-public-data.usa_names.usa_1910_current`\n",
    "    GROUP BY name\n",
    "    ORDER BY total DESC\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "arguments = {\n",
    "    'project_id': 'sandbox-235500',\n",
    "    'data_source_id': 'sandbox-235500.CLVDataset.transactions',\n",
    "    'dest_dataset_id': 'CLVDataset',\n",
    "    'dest_table_id': 'test',\n",
    "    'threshold_date': '2011-08-08',\n",
    "    'predict_end': '2011-12-12',\n",
    "    'max_monetary': '15000'\n",
    "}\n",
    "\n",
    "\n",
    "HOST = 'http://localhost:8082/api/v1/namespaces/kubeflow/services/ml-pipeline:8888/proxy'\n",
    "EXPERIMENT_NAME = 'TEST_EXP'\n",
    "\n",
    "client = kfp.Client(HOST)\n",
    "experiment = client.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "#Submit a pipeline run\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)\n",
    "print(run_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kfp",
   "language": "python",
   "name": "kfp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
