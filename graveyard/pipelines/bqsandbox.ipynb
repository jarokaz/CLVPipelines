{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID='sandbox-235500'\n",
    "DATASET_ID='CLVDataset'\n",
    "TABLE_NAME='features'\n",
    "TRANSACTIONS_TABLE_ID='sandbox-235500.CLVDataset.transactions'\n",
    "THRESHOLD_DATE = '2011-08-08'\n",
    "PREDICT_END = '2011-12-12'\n",
    "MAX_MONETARY = '15000'\n",
    "PREPROCESS_QUERY_TEMPLATE = '../components/prep_data/src/preprocess.sql'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH\n",
      "  order_summaries as (\n",
      "    SELECT\n",
      "      a.customer_id,\n",
      "      a.order_date,\n",
      "      a.order_value,\n",
      "      a.order_qty_articles\n",
      "    FROM\n",
      "    (\n",
      "      SELECT\n",
      "        customer_id,\n",
      "        order_date,\n",
      "        ROUND(SUM(unit_price * quantity), 2) AS order_value,\n",
      "        SUM(quantity) AS order_qty_articles,\n",
      "        (\n",
      "          SELECT\n",
      "            MAX(order_date)\n",
      "          FROM\n",
      "            `sandbox-235500.CLVDataset.transactions` tl\n",
      "          WHERE\n",
      "            tl.customer_id = t.customer_id\n",
      "        ) latest_order\n",
      "      FROM\n",
      "        `sandbox-235500.CLVDataset.transactions` t\n",
      "      GROUP BY\n",
      "          customer_id,\n",
      "          order_date\n",
      "    ) a\n",
      "\n",
      "    INNER JOIN (\n",
      "      -- Only customers with more than one positive order values before threshold.\n",
      "      SELECT\n",
      "        customer_id\n",
      "      FROM (\n",
      "        -- Customers and how many positive order values  before threshold.\n",
      "        SELECT\n",
      "          customer_id,\n",
      "          SUM(positive_value) cnt_positive_value\n",
      "        FROM (\n",
      "          -- Customer with whether order was positive or not at each date.\n",
      "          SELECT\n",
      "            customer_id,\n",
      "            (\n",
      "              CASE\n",
      "                WHEN SUM(unit_price * quantity) > 0 THEN 1\n",
      "                ELSE 0\n",
      "              END ) positive_value\n",
      "          FROM\n",
      "            `sandbox-235500.CLVDataset.transactions`\n",
      "          WHERE\n",
      "            order_date < DATE(\"2011-08-08\")\n",
      "          GROUP BY\n",
      "            customer_id,\n",
      "            order_date)\n",
      "        GROUP BY\n",
      "          customer_id )\n",
      "      WHERE\n",
      "        cnt_positive_value > 1\n",
      "      ) b\n",
      "    ON\n",
      "      a.customer_id = b.customer_id\n",
      "    --[START common_clean]\n",
      "    WHERE\n",
      "      -- Bought in the past 3 months\n",
      "      DATE_DIFF(DATE(\"2011-12-12\"), latest_order, DAY) <= 90\n",
      "      -- Make sure returns are consistent.\n",
      "      AND (\n",
      "        (order_qty_articles > 0 and order_Value > 0) OR\n",
      "        (order_qty_articles < 0 and order_Value < 0)\n",
      "      ))\n",
      "          \n",
      "SELECT\n",
      "  tf.customer_id,\n",
      "  -- For training period\n",
      "  -- Copying the calculations from Lifetimes where first orders are ignored\n",
      "  -- See https://github.com/CamDavidsonPilon/lifetimes/blob/master/lifetimes/utils.py#L246\n",
      "--[START features_target]\n",
      "  ROUND(tf.monetary, 2) as monetary,\n",
      "  tf.cnt_orders AS frequency,\n",
      "  tf.recency,\n",
      "  tf.T,\n",
      "  ROUND(tf.recency/cnt_orders, 2) AS time_between,\n",
      "  ROUND(tf.avg_basket_value, 2) AS avg_basket_value,\n",
      "  ROUND(tf.avg_basket_size, 2) AS avg_basket_size,\n",
      "  tf.cnt_returns,\n",
      "  -- Target calculated for overall period\n",
      "  ROUND(tt.target_monetary, 2) as target_monetary\n",
      "--[END features_target]\n",
      "FROM\n",
      "  -- This SELECT uses only data before threshold to make features.\n",
      "  (\n",
      "    SELECT\n",
      "      customer_id,\n",
      "      SUM(order_value) AS monetary,\n",
      "      DATE_DIFF(MAX(order_date), MIN(order_date), DAY) AS recency,\n",
      "      DATE_DIFF(DATE('2011-08-08'), MIN(order_date), DAY) AS T,\n",
      "      COUNT(DISTINCT order_date) AS cnt_orders,\n",
      "      AVG(order_qty_articles) avg_basket_size,\n",
      "      AVG(order_value) avg_basket_value,\n",
      "      SUM(CASE\n",
      "          WHEN order_value < 1 THEN 1\n",
      "          ELSE 0 END) AS cnt_returns\n",
      "    FROM\n",
      "      -- Makes the order value = 0 if it is the first one\n",
      "      (\n",
      "        SELECT\n",
      "          a.*,\n",
      "          (CASE\n",
      "              WHEN a.order_date = c.order_date_min THEN 0\n",
      "              ELSE a.order_value END) AS order_value_btyd\n",
      "        FROM\n",
      "          order_summaries a\n",
      "        INNER JOIN (\n",
      "          SELECT\n",
      "            customer_id,\n",
      "            MIN(order_date) AS order_date_min\n",
      "          FROM\n",
      "            order_summaries\n",
      "          GROUP BY\n",
      "            customer_id) c\n",
      "        ON\n",
      "          c.customer_id = a.customer_id\n",
      "      )\n",
      "    WHERE\n",
      "      order_date <= DATE('2011-08-08')\n",
      "    GROUP BY\n",
      "      customer_id) tf,\n",
      "\n",
      "  -- This SELECT uses all records to calculate the target (could also use data after threshold )\n",
      "  (\n",
      "    SELECT\n",
      "      customer_id,\n",
      "      SUM(order_value) target_monetary\n",
      "    FROM\n",
      "      order_summaries\n",
      "      --WHERE order_date > DATE('2011-08-08')\n",
      "    GROUP BY\n",
      "      customer_id) tt\n",
      "WHERE\n",
      "  tf.customer_id = tt.customer_id\n",
      "  AND tf.monetary > 0\n",
      "  AND tf.monetary <= 15000\n"
     ]
    }
   ],
   "source": [
    "with open(PREPROCESS_QUERY_TEMPLATE, 'r') as f:\n",
    "        query_template = f.read()\n",
    "        \n",
    "query = query_template.format(\n",
    "    transactions_table_id=TRANSACTIONS_TABLE_ID,\n",
    "    threshold_date=THRESHOLD_DATE,\n",
    "    predict_end=PREDICT_END,\n",
    "    max_monetary=MAX_MONETARY)\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT * from 3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query.format(table_id='3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(('16525', datetime.date(2011, 5, 10), 124.28, 356), {'customer_id': 0, 'order_date': 1, 'order_value': 2, 'order_qty_articles': 3})\n",
      "Row(('14397', datetime.date(2011, 5, 10), 165.44, 184), {'customer_id': 0, 'order_date': 1, 'order_value': 2, 'order_qty_articles': 3})\n",
      "Row(('16357', datetime.date(2011, 5, 10), 137.9, 22), {'customer_id': 0, 'order_date': 1, 'order_value': 2, 'order_qty_articles': 3})\n",
      "Row(('12901', datetime.date(2011, 5, 10), -208.8, -1200), {'customer_id': 0, 'order_date': 1, 'order_value': 2, 'order_qty_articles': 3})\n",
      "Row(('13592', datetime.date(2011, 5, 10), 95.94, 38), {'customer_id': 0, 'order_date': 1, 'order_value': 2, 'order_qty_articles': 3})\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "job_config = bigquery.QueryJobConfig(PROJECT_ID)\n",
    "table_ref = client.dataset(DATASET_ID).table(TABLE_NAME)\n",
    "job_config.destination = table_ref\n",
    "job_config.create_disposition = bigquery.job.CreateDisposition.CREATE_IF_NEEDED\n",
    "job_config.write_disposition = bigquery.job.WriteDisposition.WRITE_TRUNCATE\n",
    "\n",
    "\n",
    "\n",
    "query_job = client.query(QUERY, location='US', job_config=job_config)  # API request\n",
    "rows = iter(query_job.result())  # Waits for query to finish\n",
    "\n",
    "for _ in range(5):\n",
    "    print(next(rows))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSELECT\\n  tf.customer_id,\\n  -- For training period\\n  -- Copying the calculations from Lifetimes where first orders are ignored\\n  -- See https://github.com/CamDavidsonPilon/lifetimes/blob/master/lifetimes/utils.py#L246\\n--[START features_target]\\n  tf.monetary_dnn,\\n  tf.cnt_orders AS frequency_dnn,\\n  tf.cnt_orders - 1 AS frequency_btyd,\\n  tf.recency,\\n  tf.T,\\n  ROUND(tf.recency/cnt_orders, 2) AS time_between,\\n  ROUND(tf.avg_basket_value, 2) AS avg_basket_value,\\n  ROUND(tf.avg_basket_size, 2) AS avg_basket_size,\\n  tf.cnt_returns,\\n  -- Target calculated for overall period\\n  ROUND(tt.target_monetary, 2) as target_monetary\\n--[END features_target]\\nFROM\\n  -- This SELECT uses only data before threshold to make features.\\n  (\\n    SELECT\\n      customer_id,\\n      SUM(order_value) AS monetary_dnn,\\n      DATE_DIFF(MAX(order_date), MIN(order_date), DAY) AS recency,\\n      DATE_DIFF(DATE('2011-08-08'), MIN(order_date), DAY) AS T,\\n      COUNT(DISTINCT order_date) AS cnt_orders,\\n      AVG(order_qty_articles) avg_basket_size,\\n      AVG(order_value) avg_basket_value,\\n      SUM(CASE\\n          WHEN order_value < 1 THEN 1\\n          ELSE 0 END) AS cnt_returns\\n    FROM\\n      -- Makes the order value = 0 if it is the first one\\n      (\\n        SELECT\\n          a.*,\\n          (CASE\\n              WHEN a.order_date = c.order_date_min THEN 0\\n              ELSE a.order_value END) AS order_value_btyd\\n        FROM\\n          `sandbox-235500.CLVDataset.data_cleaned` a\\n        INNER JOIN (\\n          SELECT\\n            customer_id,\\n            MIN(order_date) AS order_date_min\\n          FROM\\n            `sandbox-235500.CLVDataset.data_cleaned`\\n          GROUP BY\\n            customer_id) c\\n        ON\\n          c.customer_id = a.customer_id\\n      )\\n    WHERE\\n      order_date <= DATE('2011-08-08')\\n    GROUP BY\\n      customer_id) tf,\\n\\n  -- This SELECT uses all records to calculate the target (could also use data after threshold )\\n  (\\n    SELECT\\n      customer_id,\\n      SUM(order_value) target_monetary\\n    FROM\\n      `sandbox-235500.CLVDataset.data_cleaned`\\n      --WHERE order_date > DATE('2011-08-08')\\n    GROUP BY\\n      customer_id) tt\\nWHERE\\n  tf.customer_id = tt.customer_id\\n  AND tf.monetary_dnn > 0\\n  AND tf.monetary_dnn <= 15000\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT\n",
    "  tf.customer_id,\n",
    "  -- For training period\n",
    "  -- Copying the calculations from Lifetimes where first orders are ignored\n",
    "  -- See https://github.com/CamDavidsonPilon/lifetimes/blob/master/lifetimes/utils.py#L246\n",
    "--[START features_target]\n",
    "  tf.monetary_dnn,\n",
    "  tf.cnt_orders AS frequency_dnn,\n",
    "  tf.cnt_orders - 1 AS frequency_btyd,\n",
    "  tf.recency,\n",
    "  tf.T,\n",
    "  ROUND(tf.recency/cnt_orders, 2) AS time_between,\n",
    "  ROUND(tf.avg_basket_value, 2) AS avg_basket_value,\n",
    "  ROUND(tf.avg_basket_size, 2) AS avg_basket_size,\n",
    "  tf.cnt_returns,\n",
    "  -- Target calculated for overall period\n",
    "  ROUND(tt.target_monetary, 2) as target_monetary\n",
    "--[END features_target]\n",
    "FROM\n",
    "  -- This SELECT uses only data before threshold to make features.\n",
    "  (\n",
    "    SELECT\n",
    "      customer_id,\n",
    "      SUM(order_value) AS monetary_dnn,\n",
    "      DATE_DIFF(MAX(order_date), MIN(order_date), DAY) AS recency,\n",
    "      DATE_DIFF(DATE('<<threshold_date>>'), MIN(order_date), DAY) AS T,\n",
    "      COUNT(DISTINCT order_date) AS cnt_orders,\n",
    "      AVG(order_qty_articles) avg_basket_size,\n",
    "      AVG(order_value) avg_basket_value,\n",
    "      SUM(CASE\n",
    "          WHEN order_value < 1 THEN 1\n",
    "          ELSE 0 END) AS cnt_returns\n",
    "    FROM\n",
    "      -- Makes the order value = 0 if it is the first one\n",
    "      (\n",
    "        SELECT\n",
    "          a.*,\n",
    "          (CASE\n",
    "              WHEN a.order_date = c.order_date_min THEN 0\n",
    "              ELSE a.order_value END) AS order_value_btyd\n",
    "        FROM\n",
    "          `<<project_id>>.<<dataset_id>>.data_cleaned` a\n",
    "        INNER JOIN (\n",
    "          SELECT\n",
    "            customer_id,\n",
    "            MIN(order_date) AS order_date_min\n",
    "          FROM\n",
    "            `<<project_id>>.<<dataset_id>>.data_cleaned`\n",
    "          GROUP BY\n",
    "            customer_id) c\n",
    "        ON\n",
    "          c.customer_id = a.customer_id\n",
    "      )\n",
    "    WHERE\n",
    "      order_date <= DATE('<<threshold_date>>')\n",
    "    GROUP BY\n",
    "      customer_id) tf,\n",
    "\n",
    "  -- This SELECT uses all records to calculate the target (could also use data after threshold )\n",
    "  (\n",
    "    SELECT\n",
    "      customer_id,\n",
    "      SUM(order_value) target_monetary\n",
    "    FROM\n",
    "      `<<project_id>>.<<dataset_id>>.data_cleaned`\n",
    "      --WHERE order_date > DATE('<<threshold_date>>')\n",
    "    GROUP BY\n",
    "      customer_id) tt\n",
    "WHERE\n",
    "  tf.customer_id = tt.customer_id\n",
    "  AND tf.monetary_dnn > 0\n",
    "  AND tf.monetary_dnn <= <<max_monetary>>\n",
    "\n",
    "'''\n",
    "\n",
    "max_monetary = \"15000\"\n",
    "\n",
    "QUERY = QUERY.replace(\"<<threshold_date>>\", threshold_date)\n",
    "QUERY = QUERY.replace(\"<<predict_date>>\", predict_date)\n",
    "QUERY = QUERY.replace(\"<<project_id>>\", project_id)\n",
    "QUERY = QUERY.replace(\"<<dataset_id>>\", dataset_id)\n",
    "QUERY = QUERY.replace(\"<<max_monetary>>\", max_monetary)\n",
    "QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(('13461', 884.2, 2, 1, 25, 40, 12.5, 442.1, 418.0, 0, 1445.0), {'customer_id': 0, 'monetary_dnn': 1, 'frequency_dnn': 2, 'frequency_btyd': 3, 'recency': 4, 'T': 5, 'time_between': 6, 'avg_basket_value': 7, 'avg_basket_size': 8, 'cnt_returns': 9, 'target_monetary': 10})\n",
      "Row(('16442', 437.03, 2, 1, 133, 237, 66.5, 218.51, 177.0, 0, 616.79), {'customer_id': 0, 'monetary_dnn': 1, 'frequency_dnn': 2, 'frequency_btyd': 3, 'recency': 4, 'T': 5, 'time_between': 6, 'avg_basket_value': 7, 'avg_basket_size': 8, 'cnt_returns': 9, 'target_monetary': 10})\n",
      "Row(('14456', 636.65, 2, 1, 11, 19, 5.5, 318.32, 288.0, 0, 3047.63), {'customer_id': 0, 'monetary_dnn': 1, 'frequency_dnn': 2, 'frequency_btyd': 3, 'recency': 4, 'T': 5, 'time_between': 6, 'avg_basket_value': 7, 'avg_basket_size': 8, 'cnt_returns': 9, 'target_monetary': 10})\n",
      "Row(('17516', 455.21, 2, 1, 68, 162, 34.0, 227.6, 154.5, 0, 768.08), {'customer_id': 0, 'monetary_dnn': 1, 'frequency_dnn': 2, 'frequency_btyd': 3, 'recency': 4, 'T': 5, 'time_between': 6, 'avg_basket_value': 7, 'avg_basket_size': 8, 'cnt_returns': 9, 'target_monetary': 10})\n",
      "Row(('17420', 391.51, 2, 1, 202, 250, 101.0, 195.75, 84.5, 0, 598.83), {'customer_id': 0, 'monetary_dnn': 1, 'frequency_dnn': 2, 'frequency_btyd': 3, 'recency': 4, 'T': 5, 'time_between': 6, 'avg_basket_value': 7, 'avg_basket_size': 8, 'cnt_returns': 9, 'target_monetary': 10})\n"
     ]
    }
   ],
   "source": [
    "feature_table = 'features'\n",
    "project_id = 'sandbox-235500'\n",
    "dataset_id = \"CLVDataset\"\n",
    "\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "table_ref = client.dataset(dataset_id).table(feature_table)\n",
    "job_config.destination = table_ref\n",
    "job_config.create_disposition = bigquery.job.CreateDisposition.CREATE_IF_NEEDED\n",
    "job_config.write_disposition = bigquery.job.WriteDisposition.WRITE_TRUNCATE\n",
    "\n",
    "query_job = client.query(QUERY, location='US', job_config=job_config)  # API request\n",
    "rows = iter(query_job.result())  # Waits for query to finish\n",
    "\n",
    "\n",
    "for _ in range(5):\n",
    "    print(next(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "output_file = 'test/outputs.txt'\n",
    "\n",
    "Path(output_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "Path(output_file).write_text('blabla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
