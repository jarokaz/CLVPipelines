{"cells":[{"source":"# Change directory to VSCode workspace root so that relative path loads work correctly. Turn this addition off with the DataScience.changeDirOnImportExport setting\nimport os\ntry:\n\tos.chdir(os.path.join(os.getcwd(), '../..'))\n\tprint(os.getcwd())\nexcept:\n\tpass\n","cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["import kfp\n","from kfp import compiler\n","import kfp.dsl as dsl\n","import kfp.gcp as gcp\n","\n","EXPERIMENT_NAME = 'CLV_DATAPROC'\n","CREATE_DATAPROC_SPEC_URI = 'https://raw.githubusercontent.com/kubeflow/pipelines/d2f5cc92a46012b9927209e2aaccab70961582dc/components/gcp/dataproc/create_cluster/component.yaml'\n","DELETE_DATAPROC_SPEC_URI = 'https://raw.githubusercontent.com/kubeflow/pipelines/d2f5cc92a46012b9927209e2aaccab70961582dc/components/gcp/dataproc/delete_cluster/component.yaml' \n","SUBMIT_PYSPARK_JOB_SPEC_URI = 'https://raw.githubusercontent.com/kubeflow/pipelines/d2f5cc92a46012b9927209e2aaccab70961582dc/components/gcp/dataproc/submit_pyspark_job/component.yaml'\n","AML_IMPORT_DATASET_SPEC_URI = '/home/jupyter/projects/clv_kfp/components/automl_tables/aml-import-dataset.yaml'\n","AML_TRAIN_MODEL_SPEC_URI = '/home/jupyter/projects/clv_kfp/components/automl_tables/aml-train-model.yaml'\n","CREATE_FEATURES_FILE_URI = 'gs://sandbox-235500/pyspark-scripts/create_features.py'\n","HOST = 'http://localhost:8082/api/v1/namespaces/kubeflow/services/ml-pipeline:8888/proxy'\n","\n","@dsl.pipeline(\n","    name='CLVTrainingPipelineDataproc',\n","    description='CLV Training Pipeline using Dataproc/Spark for data preparation'\n",")\n","def clv_dataproc_pipeline(\n","    project_id='', \n","    region='',\n","    source_gcs_path='',\n","    output_gcs_path='',\n","    threshold_date='',\n","    predict_end='',\n","    max_monetary=15000,\n","    max_partitions=2):\n","\n","    dataproc_create_cluster_op = kfp.components.load_component_from_url(CREATE_DATAPROC_SPEC_URI)    \n","    dataproc_delete_cluster_op = kfp.components.load_component_from_url(DELETE_DATAPROC_SPEC_URI)    \n","    dataproc_submit_pyspark_job_op = kfp.components.load_component_from_url(SUBMIT_PYSPARK_JOB_SPEC_URI)    \n","\n","    args = ('['\n","        '\"--source-gcs-path={}\",'\n","        '\"--output-gcs-path={}\",'\n","        '\"--threshold-date={}\",'\n","        '\"--predict-end={}\",'\n","        '\"--max-monetary={}\",'\n","        '\"--max-partitions={}\",'\n","        ']'\n","    ).format(\n","        source_gcs_path, \n","        output_gcs_path,\n","        threshold_date,\n","        predict_end,\n","        max_monetary,\n","        max_partitions)\n","\n","    dataproc_create_cluster_task = dataproc_create_cluster_op(\n","        project_id=project_id,\n","        region=region,\n","        name='',\n","        name_prefix='',\n","        initialization_actions='',\n","        config_bucket='',\n","        image_version='',\n","        cluster='',\n","        wait_interval='30'\n","    ) \n","\n","    dataproc_submit_pyspark_job_task = dataproc_submit_pyspark_job_op(\n","        project_id=project_id,\n","        region=region,\n","        cluster_name=dataproc_create_cluster_task.output,\n","        main_python_file_uri = CREATE_FEATURES_FILE_URI,\n","        args=args,\n","        pyspark_job='{}',\n","        job='{}',\n","        wait_interval='30'\n","    ).apply(gcp.use_gcp_secret('user-gcp-sa'))\n","\n","    dataproc_delete_cluster_task = dataproc_delete_cluster_op(\n","        project_id=project_id,\n","        region=region,\n","        name=dataproc_create_cluster_task.output\n","    )\n","\n","    dataproc_delete_cluster_task.after(dataproc_submit_pyspark_job_task)\n","\n","pipeline_func = clv_dataproc_pipeline\n","pipeline_filename = pipeline_func.__name__ + '.tar.gz'\n","\n","kfp.compiler.Compiler().compile(pipeline_func, pipeline_filename) \n","\n","\n","#Get or create and experiment\n","client = kfp.Client(HOST)\n","experiment = client.create_experiment(EXPERIMENT_NAME)\n","\n","#Submit the pipeline for execution\n","arguments = {\n","    'project_id': 'sandbox-235500',\n","    'region': 'us-west2',\n","    'source_gcs_path': 'gs://sandbox-235500/clv_sales_transactions',\n","    'output_gcs_path': 'gs://sandbox-235500/clv_training_dataset',\n","    'threshold_date': '2011-08-08',\n","    'predict_end': '2011-12-12' \n","}\n","\n","run_name = pipeline_func.__name__ + ' run'\n","run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)\n","print(run_result)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}