{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import compiler\n",
    "import kfp.dsl as dsl\n",
    "import kfp.gcp as gcp\n",
    "\n",
    "EXPERIMENT_NAME = 'CLV_TRAIN_DATAPROC'\n",
    "CREATE_DATAPROC_SPEC_URI = 'https://raw.githubusercontent.com/kubeflow/pipelines/d2f5cc92a46012b9927209e2aaccab70961582dc/components/gcp/dataproc/create_cluster/component.yaml'\n",
    "DELETE_DATAPROC_SPEC_URI = 'https://raw.githubusercontent.com/kubeflow/pipelines/d2f5cc92a46012b9927209e2aaccab70961582dc/components/gcp/dataproc/delete_cluster/component.yaml' \n",
    "SUBMIT_PYSPARK_JOB_SPEC_URI = 'https://raw.githubusercontent.com/kubeflow/pipelines/d2f5cc92a46012b9927209e2aaccab70961582dc/components/gcp/dataproc/submit_pyspark_job/component.yaml'\n",
    "AML_IMPORT_DATASET_SPEC_URI = '/home/jupyter/projects/clv_kfp/components/automl_tables/aml-import-dataset.yaml'\n",
    "AML_TRAIN_MODEL_SPEC_URI = '/home/jupyter/projects/clv_kfp/components/automl_tables/aml-train-model.yaml'\n",
    "CREATE_FEATURES_FILE_URI = 'gs://sandbox-235500/pyspark-scripts/create_features.py'\n",
    "HOST = 'http://localhost:8082'\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='CLVTrainingPipelineDataproc',\n",
    "    description='CLV Training Pipeline using Dataproc/Spark for data preparation'\n",
    ")\n",
    "def clv_dataproc_pipeline(\n",
    "    project_id='', \n",
    "    region='us-central1',\n",
    "    source_gcs_path='',\n",
    "    output_gcs_path='',\n",
    "    threshold_date='',\n",
    "    predict_end='',\n",
    "    max_monetary=15000,\n",
    "    max_partitions=2):\n",
    "\n",
    "    dataproc_create_cluster_op = kfp.components.load_component_from_url(CREATE_DATAPROC_SPEC_URI)    \n",
    "    dataproc_delete_cluster_op = kfp.components.load_component_from_url(DELETE_DATAPROC_SPEC_URI)    \n",
    "    dataproc_submit_pyspark_job_op = kfp.components.load_component_from_url(SUBMIT_PYSPARK_JOB_SPEC_URI)    \n",
    "\n",
    "    args = ('['\n",
    "        '\"--source-gcs-path={}\",'\n",
    "        '\"--output-gcs-path={}\",'\n",
    "        '\"--threshold-date={}\",'\n",
    "        '\"--predict-end={}\",'\n",
    "        '\"--max-monetary={}\",'\n",
    "        '\"--max-partitions={}\",'\n",
    "        ']'\n",
    "    ).format(\n",
    "        source_gcs_path, \n",
    "        output_gcs_path,\n",
    "        threshold_date,\n",
    "        predict_end,\n",
    "        max_monetary,\n",
    "        max_partitions)\n",
    "\n",
    "    dataproc_create_cluster_task = dataproc_create_cluster_op(\n",
    "        project_id=project_id,\n",
    "        region=region,\n",
    "        name='',\n",
    "        name_prefix='',\n",
    "        initialization_actions='',\n",
    "        config_bucket='',\n",
    "        image_version='',\n",
    "        cluster='',\n",
    "        wait_interval='30'\n",
    "    ) \n",
    "\n",
    "    dataproc_submit_pyspark_job_task = dataproc_submit_pyspark_job_op(\n",
    "        project_id=project_id,\n",
    "        region=region,\n",
    "        cluster_name=dataproc_create_cluster_task.output,\n",
    "        main_python_file_uri = CREATE_FEATURES_FILE_URI,\n",
    "        args=args,\n",
    "        pyspark_job='{}',\n",
    "        job='{}',\n",
    "        wait_interval='30'\n",
    "    )\n",
    "\n",
    "    dataproc_delete_cluster_task = dataproc_delete_cluster_op(\n",
    "        project_id=project_id,\n",
    "        region=region,\n",
    "        name=dataproc_create_cluster_task.output\n",
    "    )\n",
    "\n",
    "    dataproc_delete_cluster_task.after(dataproc_submit_pyspark_job_task)\n",
    "    \n",
    "    import_dataset_task = import_dataset_op(\n",
    "        project_id=project_id,\n",
    "        location=region,\n",
    "        dataset_name=automl_dataset_name,\n",
    "        source_data_uri='bq://{}.{}.{}'.format(project_id, features_dataset_id, features_table_id)\n",
    "    )\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "pipeline_func = clv_dataproc_pipeline\n",
    "pipeline_filename = pipeline_func.__name__ + '.tar.gz'\n",
    "\n",
    "kfp.compiler.Compiler().compile(pipeline_func, pipeline_filename) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"http://localhost:8082/#/experiments/details/db6928e8-05cf-4a25-8787-95bf3466b756\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://localhost:8082/#/runs/details/501390db-7a5c-11e9-bf5c-42010a8a0028\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': datetime.datetime(2019, 5, 19, 17, 34, 11, tzinfo=tzlocal()),\n",
      " 'description': None,\n",
      " 'error': None,\n",
      " 'finished_at': datetime.datetime(1970, 1, 1, 0, 0, tzinfo=tzlocal()),\n",
      " 'id': '501390db-7a5c-11e9-bf5c-42010a8a0028',\n",
      " 'metrics': None,\n",
      " 'name': 'clv_dataproc_pipeline run',\n",
      " 'pipeline_spec': {'parameters': [{'name': 'project-id',\n",
      "                                   'value': 'sandbox-235500'},\n",
      "                                  {'name': 'threshold-date',\n",
      "                                   'value': '2011-08-08'},\n",
      "                                  {'name': 'predict-end',\n",
      "                                   'value': '2011-12-12'},\n",
      "                                  {'name': 'region', 'value': 'us-west2'},\n",
      "                                  {'name': 'output-gcs-path',\n",
      "                                   'value': 'gs://sandbox-235500/clv_training_dataset'},\n",
      "                                  {'name': 'source-gcs-path',\n",
      "                                   'value': 'gs://sandbox-235500/clv_sales_transactions'}],\n",
      "                   'pipeline_id': None,\n",
      "                   'pipeline_manifest': None,\n",
      "                   'workflow_manifest': '{\"apiVersion\": '\n",
      "                                        '\"argoproj.io/v1alpha1\", \"kind\": '\n",
      "                                        '\"Workflow\", \"spec\": {\"entrypoint\": '\n",
      "                                        '\"clvtrainingpipelinedataproc\", '\n",
      "                                        '\"templates\": [{\"dag\": {\"tasks\": '\n",
      "                                        '[{\"arguments\": {\"parameters\": '\n",
      "                                        '[{\"value\": '\n",
      "                                        '\"{{inputs.parameters.project-id}}\", '\n",
      "                                        '\"name\": \"project-id\"}, {\"value\": '\n",
      "                                        '\"{{inputs.parameters.region}}\", '\n",
      "                                        '\"name\": \"region\"}]}, \"name\": '\n",
      "                                        '\"dataproc-create-cluster\", '\n",
      "                                        '\"template\": '\n",
      "                                        '\"dataproc-create-cluster\"}, '\n",
      "                                        '{\"dependencies\": '\n",
      "                                        '[\"dataproc-create-cluster\", '\n",
      "                                        '\"dataproc-submit-pyspark-job\"], '\n",
      "                                        '\"arguments\": {\"parameters\": '\n",
      "                                        '[{\"value\": '\n",
      "                                        '\"{{tasks.dataproc-create-cluster.outputs.parameters.dataproc-create-cluster-cluster-name}}\", '\n",
      "                                        '\"name\": '\n",
      "                                        '\"dataproc-create-cluster-cluster-name\"}, '\n",
      "                                        '{\"value\": '\n",
      "                                        '\"{{inputs.parameters.project-id}}\", '\n",
      "                                        '\"name\": \"project-id\"}, {\"value\": '\n",
      "                                        '\"{{inputs.parameters.region}}\", '\n",
      "                                        '\"name\": \"region\"}]}, \"name\": '\n",
      "                                        '\"dataproc-delete-cluster\", '\n",
      "                                        '\"template\": '\n",
      "                                        '\"dataproc-delete-cluster\"}, '\n",
      "                                        '{\"dependencies\": '\n",
      "                                        '[\"dataproc-create-cluster\"], '\n",
      "                                        '\"arguments\": {\"parameters\": '\n",
      "                                        '[{\"value\": '\n",
      "                                        '\"{{tasks.dataproc-create-cluster.outputs.parameters.dataproc-create-cluster-cluster-name}}\", '\n",
      "                                        '\"name\": '\n",
      "                                        '\"dataproc-create-cluster-cluster-name\"}, '\n",
      "                                        '{\"value\": '\n",
      "                                        '\"{{inputs.parameters.max-monetary}}\", '\n",
      "                                        '\"name\": \"max-monetary\"}, {\"value\": '\n",
      "                                        '\"{{inputs.parameters.max-partitions}}\", '\n",
      "                                        '\"name\": \"max-partitions\"}, {\"value\": '\n",
      "                                        '\"{{inputs.parameters.output-gcs-path}}\", '\n",
      "                                        '\"name\": \"output-gcs-path\"}, {\"value\": '\n",
      "                                        '\"{{inputs.parameters.predict-end}}\", '\n",
      "                                        '\"name\": \"predict-end\"}, {\"value\": '\n",
      "                                        '\"{{inputs.parameters.project-id}}\", '\n",
      "                                        '\"name\": \"project-id\"}, {\"value\": '\n",
      "                                        '\"{{inputs.parameters.region}}\", '\n",
      "                                        '\"name\": \"region\"}, {\"value\": '\n",
      "                                        '\"{{inputs.parameters.source-gcs-path}}\", '\n",
      "                                        '\"name\": \"source-gcs-path\"}, {\"value\": '\n",
      "                                        '\"{{inputs.parameters.threshold-date}}\", '\n",
      "                                        '\"name\": \"threshold-date\"}]}, \"name\": '\n",
      "                                        '\"dataproc-submit-pyspark-job\", '\n",
      "                                        '\"template\": '\n",
      "                                        '\"dataproc-submit-pyspark-job\"}]}, '\n",
      "                                        '\"inputs\": {\"parameters\": [{\"name\": '\n",
      "                                        '\"max-monetary\"}, {\"name\": '\n",
      "                                        '\"max-partitions\"}, {\"name\": '\n",
      "                                        '\"output-gcs-path\"}, {\"name\": '\n",
      "                                        '\"predict-end\"}, {\"name\": '\n",
      "                                        '\"project-id\"}, {\"name\": \"region\"}, '\n",
      "                                        '{\"name\": \"source-gcs-path\"}, {\"name\": '\n",
      "                                        '\"threshold-date\"}]}, \"name\": '\n",
      "                                        '\"clvtrainingpipelinedataproc\"}, '\n",
      "                                        '{\"inputs\": {\"parameters\": [{\"name\": '\n",
      "                                        '\"project-id\"}, {\"name\": \"region\"}]}, '\n",
      "                                        '\"container\": {\"env\": [{\"value\": '\n",
      "                                        '\"{{pod.name}}\", \"name\": '\n",
      "                                        '\"KFP_POD_NAME\"}], \"args\": '\n",
      "                                        '[\"kfp_component.google.dataproc\", '\n",
      "                                        '\"create_cluster\", \"--project_id\", '\n",
      "                                        '\"{{inputs.parameters.project-id}}\", '\n",
      "                                        '\"--region\", '\n",
      "                                        '\"{{inputs.parameters.region}}\", '\n",
      "                                        '\"--name\", \"\", \"--name_prefix\", \"\", '\n",
      "                                        '\"--initialization_actions\", \"\", '\n",
      "                                        '\"--config_bucket\", \"\", '\n",
      "                                        '\"--image_version\", \"\", \"--cluster\", '\n",
      "                                        '\"\", \"--wait_interval\", \"30\"], '\n",
      "                                        '\"command\": [], \"image\": '\n",
      "                                        '\"gcr.io/ml-pipeline/ml-pipeline-gcp:3b949b37aa2cefd3180398d59116f43ce965a2a6\"}, '\n",
      "                                        '\"name\": \"dataproc-create-cluster\", '\n",
      "                                        '\"outputs\": {\"parameters\": [{\"name\": '\n",
      "                                        '\"dataproc-create-cluster-cluster-name\", '\n",
      "                                        '\"valueFrom\": {\"path\": '\n",
      "                                        '\"/tmp/kfp/output/dataproc/cluster_name.txt\"}}], '\n",
      "                                        '\"artifacts\": [{\"path\": '\n",
      "                                        '\"/mlpipeline-ui-metadata.json\", '\n",
      "                                        '\"name\": \"mlpipeline-ui-metadata\", '\n",
      "                                        '\"optional\": true}, {\"path\": '\n",
      "                                        '\"/mlpipeline-metrics.json\", \"name\": '\n",
      "                                        '\"mlpipeline-metrics\", \"optional\": '\n",
      "                                        'true}]}}, {\"inputs\": {\"parameters\": '\n",
      "                                        '[{\"name\": '\n",
      "                                        '\"dataproc-create-cluster-cluster-name\"}, '\n",
      "                                        '{\"name\": \"project-id\"}, {\"name\": '\n",
      "                                        '\"region\"}]}, \"container\": {\"env\": '\n",
      "                                        '[{\"value\": \"{{pod.name}}\", \"name\": '\n",
      "                                        '\"KFP_POD_NAME\"}], \"args\": '\n",
      "                                        '[\"kfp_component.google.dataproc\", '\n",
      "                                        '\"delete_cluster\", \"--project_id\", '\n",
      "                                        '\"{{inputs.parameters.project-id}}\", '\n",
      "                                        '\"--region\", '\n",
      "                                        '\"{{inputs.parameters.region}}\", '\n",
      "                                        '\"--name\", '\n",
      "                                        '\"{{inputs.parameters.dataproc-create-cluster-cluster-name}}\", '\n",
      "                                        '\"--wait_interval\", \"30\"], \"command\": '\n",
      "                                        '[], \"image\": '\n",
      "                                        '\"gcr.io/ml-pipeline/ml-pipeline-gcp:3b949b37aa2cefd3180398d59116f43ce965a2a6\"}, '\n",
      "                                        '\"name\": \"dataproc-delete-cluster\", '\n",
      "                                        '\"outputs\": {\"artifacts\": [{\"path\": '\n",
      "                                        '\"/mlpipeline-ui-metadata.json\", '\n",
      "                                        '\"name\": \"mlpipeline-ui-metadata\", '\n",
      "                                        '\"optional\": true}, {\"path\": '\n",
      "                                        '\"/mlpipeline-metrics.json\", \"name\": '\n",
      "                                        '\"mlpipeline-metrics\", \"optional\": '\n",
      "                                        'true}]}}, {\"inputs\": {\"parameters\": '\n",
      "                                        '[{\"name\": '\n",
      "                                        '\"dataproc-create-cluster-cluster-name\"}, '\n",
      "                                        '{\"name\": \"max-monetary\"}, {\"name\": '\n",
      "                                        '\"max-partitions\"}, {\"name\": '\n",
      "                                        '\"output-gcs-path\"}, {\"name\": '\n",
      "                                        '\"predict-end\"}, {\"name\": '\n",
      "                                        '\"project-id\"}, {\"name\": \"region\"}, '\n",
      "                                        '{\"name\": \"source-gcs-path\"}, {\"name\": '\n",
      "                                        '\"threshold-date\"}]}, \"container\": '\n",
      "                                        '{\"env\": [{\"value\": \"{{pod.name}}\", '\n",
      "                                        '\"name\": \"KFP_POD_NAME\"}], \"args\": '\n",
      "                                        '[\"kfp_component.google.dataproc\", '\n",
      "                                        '\"submit_pyspark_job\", \"--project_id\", '\n",
      "                                        '\"{{inputs.parameters.project-id}}\", '\n",
      "                                        '\"--region\", '\n",
      "                                        '\"{{inputs.parameters.region}}\", '\n",
      "                                        '\"--cluster_name\", '\n",
      "                                        '\"{{inputs.parameters.dataproc-create-cluster-cluster-name}}\", '\n",
      "                                        '\"--main_python_file_uri\", '\n",
      "                                        '\"gs://sandbox-235500/pyspark-scripts/create_features.py\", '\n",
      "                                        '\"--args\", '\n",
      "                                        '\"[\\\\\"--source-gcs-path={{inputs.parameters.source-gcs-path}}\\\\\",\\\\\"--output-gcs-path={{inputs.parameters.output-gcs-path}}\\\\\",\\\\\"--threshold-date={{inputs.parameters.threshold-date}}\\\\\",\\\\\"--predict-end={{inputs.parameters.predict-end}}\\\\\",\\\\\"--max-monetary={{inputs.parameters.max-monetary}}\\\\\",\\\\\"--max-partitions={{inputs.parameters.max-partitions}}\\\\\",]\", '\n",
      "                                        '\"--pyspark_job\", \"{}\", \"--job\", \"{}\", '\n",
      "                                        '\"--wait_interval\", \"30\"], \"command\": '\n",
      "                                        '[], \"image\": '\n",
      "                                        '\"gcr.io/ml-pipeline/ml-pipeline-gcp:3b949b37aa2cefd3180398d59116f43ce965a2a6\"}, '\n",
      "                                        '\"name\": '\n",
      "                                        '\"dataproc-submit-pyspark-job\", '\n",
      "                                        '\"outputs\": {\"parameters\": [{\"name\": '\n",
      "                                        '\"dataproc-submit-pyspark-job-job-id\", '\n",
      "                                        '\"valueFrom\": {\"path\": '\n",
      "                                        '\"/tmp/kfp/output/dataproc/job_id.txt\"}}], '\n",
      "                                        '\"artifacts\": [{\"path\": '\n",
      "                                        '\"/mlpipeline-ui-metadata.json\", '\n",
      "                                        '\"name\": \"mlpipeline-ui-metadata\", '\n",
      "                                        '\"optional\": true}, {\"path\": '\n",
      "                                        '\"/mlpipeline-metrics.json\", \"name\": '\n",
      "                                        '\"mlpipeline-metrics\", \"optional\": '\n",
      "                                        'true}]}}], \"serviceAccountName\": '\n",
      "                                        '\"pipeline-runner\", \"arguments\": '\n",
      "                                        '{\"parameters\": [{\"value\": \"\", \"name\": '\n",
      "                                        '\"project-id\"}, {\"value\": \"\", \"name\": '\n",
      "                                        '\"region\"}, {\"value\": \"\", \"name\": '\n",
      "                                        '\"source-gcs-path\"}, {\"value\": \"\", '\n",
      "                                        '\"name\": \"output-gcs-path\"}, {\"value\": '\n",
      "                                        '\"\", \"name\": \"threshold-date\"}, '\n",
      "                                        '{\"value\": \"\", \"name\": \"predict-end\"}, '\n",
      "                                        '{\"value\": \"15000\", \"name\": '\n",
      "                                        '\"max-monetary\"}, {\"value\": \"2\", '\n",
      "                                        '\"name\": \"max-partitions\"}]}}, '\n",
      "                                        '\"metadata\": {\"generateName\": '\n",
      "                                        '\"clvtrainingpipelinedataproc-\"}}'},\n",
      " 'resource_references': [{'key': {'id': 'db6928e8-05cf-4a25-8787-95bf3466b756',\n",
      "                                  'type': 'EXPERIMENT'},\n",
      "                          'relationship': 'OWNER'}],\n",
      " 'scheduled_at': datetime.datetime(1970, 1, 1, 0, 0, tzinfo=tzlocal()),\n",
      " 'status': None,\n",
      " 'storage_state': None}\n"
     ]
    }
   ],
   "source": [
    "#Get or create and experiment\n",
    "client = kfp.Client(HOST)\n",
    "experiment = client.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "#Submit the pipeline for execution\n",
    "arguments = {\n",
    "    'project_id': 'sandbox-235500',\n",
    "    'source_gcs_path': 'gs://sandbox-235500/clv_sales_transactions',\n",
    "    'output_gcs_path': 'gs://sandbox-235500/clv_training_dataset',\n",
    "    'threshold_date': '2011-08-08',\n",
    "    'predict_end': '2011-12-12' \n",
    "}\n",
    "\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)\n",
    "print(run_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
